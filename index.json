[{"content":" I have always found statistics to be pretty cool. The implications of the Central Limit Theorem (CLT) and being able to conduct hypothesis tests to make truth-y statements about the world is as phenomenal in my opinion as; something existing rather that nothing and backpropagation working as a tool to train neural networks. Statistics is one of the fundamental fields underpinning ML and DL, so it is always nice to keep those foundations strong \u0026ndash; I have always wanted to explore the difference between the Frequentist and Bayesian understandings of statistics and recently spent some time delving into the Bayesian branch. I think there are useful ideas for reasoning about the world in the Bayesian interpretation and hope you find them here.\nHistorical Background # The Bayesian school of statistics gets it\u0026rsquo;s name from Thomas Bayes an English statistician that whipped out Bayes\u0026rsquo; Theorem at some point in his lifetime, it was presented to the Royal Society in 1763 after his death by Richard Price. The theorem was presented as a solution to the \u0026ldquo;inverse probability problem\u0026rdquo;, basically the chaps of the 1700s wanted to calculate Posterior Distributions as we do with the Bayesian Theorem today.\nBayesianism as a school of thought in the more philosophical sense around the 1950s, around the dawn of the modern computer. Bayesian methods have been intertwined with computers and computation since the get go and have been used for AI; Naïve Bayes and Bayesian Belief Networks are two methods that leverage Bayes\u0026rsquo; Theorem to operate.\nBayesians and Frequentists # Frequentist statistics is the canonical form or interpretation of statistics, it boils down to the idea that the probability of some event, is described by the frequency or rate at which that event occurs. Bayesian statistics however, represents uncertainties in information with probabilities. That might sound like mumbo jumbo so here is an example of the difference in reasoning with the classic coin flip.\nAssume we have a fair coin, for which the Probability of it landing on heads after being tossed is 50% (i.e; \\(P(H)=0.5\\) ) The Frequentists would interpret this as meaning that 50 out of 100 coin flips should be heads because we expect Heads to occur at a rate of 50%, or half the time The Bayesians would interpret this as being equally unsure of the outcome for the next coin flip, it could be Heads or Not Heads with equal likelihood For toy problems where we have this sort of frequency of events to work with there isn\u0026rsquo;t an obvious advantage to thinking like a Bayesian, but the Bayesian perspective makes far more sense when we are examining outcomes for which many observations do not exist. Say you hear an odd sound after driving through a construction area and your car veers toward one side. You want to estimate the probability of this behavior being due to a flat tire, since you never have been in this situation before you have no outcomes to use as prior proabilities \u0026ndash; meaning that a frequentist interpretation of this problem is effectively undefined. We can estimate our belief in the probability of the odd behavior being due to a flat tire in a Bayesian sense. This makes the Bayesian framework amenable to more real world problems for which many occurences is not tractable.\nProbability Formals # Probability can be thought of as an extension of Logic; extending logical reasoning from discrete space into continuous.\nLogic is all about working with absolute beliefs, things in logic are either; True or False, in Discrete states of 0 or 1. A really effective and interesting way to think of probability is that we extend our logical reasoning into \u0026ldquo;continuous space\u0026rdquo; whereas traditional logic exists only in a discrete/binary space. This lets us extend the tools of logic into areas that would have previously been undefined or non-traversable.\nFrom a Bayesian perspective; being entirely certain that an outcome will or will not occur is equivalent to traditional logic.\n1 = 100% certain that the outcome will occur, 0 = 100% certain that the outcome will not occur. This ability to reason about likelihood of outcomes gets extended in probability, where we can explicitly define the probability of an outcome without needing it to be entirely certain one way or the other. A slightly biased coin might be have outcome probabilities of P(H)=0.85 and P(T)=0.15, there is not a discrete mapping for each outcome (since always heads or always tails doesn\u0026rsquo;t exist) but we can reason about outcomes in a logical way using these probabilities and statistics.\nIn Logic we have operators for reasoning, these are \\( \\in \\lbrace AND, OR, NOT \\rbrace \\) and their descriptive natural language counterparts: Conjunction, Disjunction, Negation \u0026ndash; which when combined with True data we can reason about the world. To make the extension into the Probabilistic domain, we need to extend these operators; the mapping of Operators in Logic to their counterparts in Probability depend on whether or not the Probabilistic Operation is Independent or Dependent.\nFor Independent Probabilities; \\( AND \\mapsto P(A) * P(B) \\) \u0026ndash; (also referred to as the \u0026ldquo;product of probabilities\u0026rdquo;), often represented as \\( P(A, B) \\) in notation \\( OR \\mapsto P(A) \\ or \\ P(B) = P(A) + P(B) \\) \u0026ndash; (the probability of event A or B occuring) \\( NOT \\mapsto \\neg P(A) = 1 - P(A) ; \\) \u0026ndash; (the \u0026ldquo;¬\u0026rdquo; symbol refers to \u0026ldquo;the negation of\u0026rdquo;, in this case the negation of the Probability of A is equal to 1-P(A), effectively the probability of not A) For Dependent Probabilities; \\( AND \\mapsto P(A) * P(B | A) ; \\) \u0026ndash; this slight difference in the \\( AND \\) operator is noteworthy, as we need to account for the dependence between the variables, the product of the two events happening then becomes the probability of the event we are interested in, A, occuring. Multiplied with the probability of B occuring, GIVEN that A has already occured. (in the independent scenario, there is no conditioning so we can just multiply the probabilities for A and B, technically we do the same thing as the dependent setting but since there is no mutual inclusitivity/dependence we just multiply by the probability of B). \\( OR \\mapsto P(A) \\ or \\ P(B) = P(A) + P(B) - P(A, B) \\) \u0026ndash; the subtraction of the \\( P(A, B) \\) term is the only change from the dependent variant, the reason for it is that we have co-occuring variables, because they are dependent on one another we need to factor in the probability of A and B occuring when we want to calculate ther probability of either A or B occuring. the not operation remains the same we use this when dealing with a single variable so it doesn\u0026rsquo;t require factoring any dependence into the definition Most of reality involves working with Dependent probabilities (mutually inclusive) and Independent Probabilities (mutually exclusive) can be thought of as special cases of the Dependent counterparts (since the formulas for these are simplified from the dependent definition). We use these methods of combining probabilities to extend logic into the probabilistic domain.\nBreakdown of Bayes Theorem # Bayes Theorem is a tool for reversing conditional probabilities, that is given the probability of an observation given a belief, \\( P(Observation|Belief) \\) we can quantify our strength in believing the belief, given the observation ( \\( P(Belief | Observation) \\) ). This gets formulated frequently in the world as \\( P(X | y)\\) wherein; \\( X=data \\) and \\( y=label \\). This formulation corresponds to estimating the likelihood of a single instance of data being from class \\( y \\) when conditioned on the observations associated with it, think Spam or Not Spam Email as our classes and the Data being the tokenized words from the email.\nBayes Theorem can be broken down as follows:\nThe Theorem \\( P(A | B) = \\frac{P(A) * P(B | A)}{P(B)} \\) The Components \\( P(A|B) \\) \u0026ndash; the Posterior Probability, thing we are interested in calculating (likelihood of observation being from class \\( y \\) \\( P(B | A) \\) \u0026ndash; the Likelihood, is our probability of an observation occuring given our Prior (given class \\(y \\) the likelihood of the observing the data) \\( P(A) \\) \u0026ndash; the Prior Probability, the probability of our Prior occuring (just the data being observed) \\( P(B) \\) \u0026ndash; the Data, this normalizes our calculation (without which we would have unnormalized probabilities) The Terms; Prior and Belief, can kind of be used interchangably, fundamentally they refer to our background information that when combined with data lets us calculate the probability of the belief being the case (say the probability of fraud occuring given some set of data, this is the prior/belief that we want to estimate a probability of occurence for given some observed data) Unormalized Posterior Comparison of Cakes # If we forgo the normalization (dividing by likelihood of data) we can still get meaningful insights from comparing two, unormalized, Bayesian Posteriors (doing just the top portion of the theorems\u0026rsquo; calculation) \u0026ndash; this is done by comparing the ratios to one another, here is an example: Our Priors: \\( P(cheesecake) = 0.9 \\) \\( P(angelcake) = 0.12 \\) Our Likelihoods: \\( P(cheesecake | GooeyTexture) = 0.8 \\) \\( P(angelcake | GooeyTexture) = 0.03 \\) Calculation of Unnormalized Posteriors; \\( P(cheesecake | GooeyTexture) * P(cheesecake) \\approx 0.72 = P(CB) \\) \u0026ndash;\u0026gt; belief in eating cheesecake \\( P(angelcake | GooeyTexture) * P(angelcake) \\approx 0.0036 = P(AB) \\) \u0026ndash;\u0026gt; belief in eating angelcake Relative Comparsion; \\( \\frac{P(CB)}{P(AB)} = 0.72/0.0036 = 200 \\) \u0026ndash; meaning the likelihood that we are eating cheesecake, given our data about texture and our priors for what cake we like to eat, is 200x more likely than the likelihood of us eating angelcake given the information. Being Less Wrong ~= Intelligence # Human brains seem to have evolved a general \u0026ldquo;sense\u0026rdquo; of likelihood. What we do in Day-to-Day life is something like Bayesian statistics, we estimate the likelihood of outcomes in order to influence decisions and all of our beliefs are conditioned on our priors of the world\u0026rsquo;s behavior. The probabilties and actual values that go into our active inference pipeline aren\u0026rsquo;t yet quantifiable in the same way we can parameterize a neural network, but we still think in roughly these terms.\nOur understanding of the world at say, timestep \\( t \\), is conditioned on our understanding of the world as we experienced it from \\(t_0 \\) -\u0026gt; \\( t_{t-1} \\) \u0026ndash; or in other words, all of our experience in the world from our first to most recent.\nBayesian Reasoning is a great way to formalize uncertainty and quantify our beliefs about the world. It has already been used to a fair extent within ML and in some AI Systems but I reckon that the Bayesian framework, as a tool for operating in the world, still has a part to play in building systems that reason how Humans do.\n","date":"30 October 2022","permalink":"/napkins/bayesianstats/","section":"Napkins","summary":"I have always found statistics to be pretty cool. The implications of the Central Limit Theorem (CLT) and being able to conduct hypothesis tests to make truth-y statements about the world is as phenomenal in my opinion as; something existing rather that nothing and backpropagation working as a tool to train neural networks.","title":"Bayesian Statistics"},{"content":"","date":"30 October 2022","permalink":"/","section":"CKG","summary":"","title":"CKG"},{"content":"","date":"30 October 2022","permalink":"/napkins/","section":"Napkins","summary":"","title":"Napkins"},{"content":"​\nThroughout my travels in Cyberspace; journeying across countless github repos, enduring several senseless Zoom meetings, delving into the depths of many package docs and interacting with Technical \u0026amp; Non-Technical folk alike, I have always wondered where the generally acceptable line between Machine Learning (ML) and Artificial Intelligence (AI) is to be drawn. It is a Friday Evening, I will be eating Ramen and will draw a somewhat arbitrary line in order to make what I believe is a meaningful (albeit nitpicky) distinction.\nI assume here that there is a meaningful difference between the two terms, one could certainly argue that ML is AI, but I think that it might be more sensical to say that AI leverages or is one application of ML.\n​\nDefinitions # To follow along with someone\u0026rsquo;s distinction between two things, you need a shared language to reason about what X \u0026amp; Y are and how they might differ or be similar;\nMachine Learning- a set of quasi-statistical, Mathematical and Computer Science-esque techniques for \u0026ldquo;learning\u0026rdquo; useful things from data Artificial Intelligence- a Man-made system that accomplishes some task rooted in the leveraging of knowledge These are not Merriam-Webster\u0026rsquo;s words but these definitions follow the jist of the respective ideas as presented in our Cornucopia of knowledge, Wikipedia; ML and AI\nAI in particular is suited to this definition as it encompasses Modern Systems like AlphaGo as well as Good Ol\u0026rsquo; Fashioned AI like Eliza \u0026ndash; also being flexible enough to include things that do not involve \u0026ldquo;learning from data\u0026rdquo; such as Static Knowledge Bases or the wizardry yet to be discovered that leads to AGI.\n​\nThe Difference # Machine Learning techniques are brilliant at learning and AI Systems are those in which we apply knowledge \u0026ndash; that knowledge can be transfered or learned but the AI system is not itself doing the learning (an aspect of it, say the Model/Controller/Head, is). Why then is this relevant?\nFor one, some of the technical folk get angry when any system that is capable of something we might call intelligent gets called AI, be it solving protein folding or becoming the world\u0026rsquo;s most diversely skilled artist. In this frame of thought, being able to use a neural network doesn\u0026rsquo;t make you intelligent \u0026ndash; which is neither fun nor sensical. Systems like AlphaFold exhibit superhuman intelligence on tasks and are also artificial, your brain can do the sum() operation to combine your representations of these two concepts.\nThe non-technical folk also get into a ruffle when simple applications of ML expose themselves, achieving 87% accuracy on classifying the likelihood of crops going sour or reducing the dimensionality of a tabular dataset are both great applications of learning, but in vaccum are not themselves acts of intelligence. For methods leveraging Machine Learning to be intelligent, they must be implemented, and the implementation, the artificial one, is what gives birth to AI.\nIt is worth noting that the model of something like GPT-3 or Stable Diffusions is basically AI. (since they can exhibit intelligence in applications out of the box and great proficency at those applications) But the models trained alone are not intelligent, it tasks usage in a downstream application for it to exhibit intelligence, up until then it has just reduced error on some data, effectively learning something useful.\nAll in all in is nitpicky to differentiate between ML and AI \u0026ndash; but I think necessary to get all the great folks on the same page. ML is a toolkit of methods for learning and AI is the application of crafted knowledge \u0026ndash; you just use backpropagation to sculpt that knowledge.\n​\n","date":"28 October 2022","permalink":"/napkins/diff-ml-ai/","section":"Napkins","summary":"​\nThroughout my travels in Cyberspace; journeying across countless github repos, enduring several senseless Zoom meetings, delving into the depths of many package docs and interacting with Technical \u0026amp; Non-Technical folk alike, I have always wondered where the generally acceptable line between Machine Learning (ML) and Artificial Intelligence (AI) is to be drawn.","title":"The Difference between ML and AI"},{"content":"​\nContext # I have spent the last few weeks immersing myself in the Policy Optimization Literature, within the larger field of Reinforcement Learning. This branch of Machine Learning has always been my \u0026ldquo;fancy\u0026rdquo;, of the main fields in ML, RL is the most \u0026ldquo;gangster\u0026rdquo;. This affinity for the field of figuring out how to create Agents that can learn things more closely to the way that humans learn is what has prompted me to wake up a little extra early each day; diving into papers and programming before the hitting the gym and before the main work day.\nThese past 2-ish weeks have been spent trying to implement the VPG, basically what was done in Sutton\u0026rsquo;s paper from 2000 with the addition of generalized advantage estimation ( see section 4) a method for reducing variance of the Policy Gradient (effectively the \u0026ldquo;error\u0026rdquo; we want to backprop to our Policy Network parameters for learning).\n​\nJust Sit With it # The math behind the Generalized Advantage Estimate (GAE) calculation isn\u0026rsquo;t all that bad, Schulman (who is just brilliant) breaks everything down nicely in his thesis, the intuition for GAE is also a nice one; basically we want to train our Policy Network based on not all of the Reward signals but only the reward signals that come from Actions that do better than expected. It doesn\u0026rsquo;t sound all that bad and the only difference from my prior implmentation of REINFORCE is just; the introduction a Value Function estimator (second network that is trained to predict reward given states) and calculating advantage estimates for backprop in the Policy Network.\nSounds trivial, right?\nIt actually is trivial! But never underestimate your ability to be an absolute nincompoop!\nThis problem really haunted me, it was one of those kinds of things where you understand it conceptually but looking at other implementations throws off your understanding and you get caught in this loop of trying to get it to work but then second guessing your understanding and reviewing the papers and math and blah blah blah. Everyone person that does difficult things occasionally finds themself in the \u0026ldquo;spinning of the wheels\u0026rdquo;, that lovely place amongst the mud, nonsense and the sense that they should stop being; [stupid, weak, a loser, dumb, lazy, etc.] and just get it done. In these times even though you do step away and let the problem marinate you just gotta sit with the problem. Progress is still made even if code/whatever your metric of performance isn\u0026rsquo;t being increased. The mere act of enduring the muck increases your skills. Being stubborn and hitting your head against the wall or continously attempting to climb the plateau after falling is the way through. It sucks yea, and all that comes with sucking generally sucks; but the thing to remember is that it\u0026rsquo;ll pass, and with each blow you take, you also get STRONGER.\nSo just sit with the problem, don\u0026rsquo;t run the same function wondering why it doesn\u0026rsquo;t work (or at least try to refrain from doing it \u0026lt; 3 times before thinking about the error) \u0026ndash; the answer will come in due time, you can think of it as your Unconscious Self updating the gradient.\n​\nLots of Ecstatic Yelling \u0026amp; Some Jumping # After weeks of this debauchery, I sat down this lovely Autumn Sunday to do battle yet again with this. I spent the better part of an afternoon implementing GAE in my VPG with no luck.\nI tried the discounted cumsum trick, grads didn\u0026rsquo;t get tracked correctly I tried to do the compute with vectors as opposed to elementwise, issues with the discount cumsum calculation I tried to do everything elementwise, Tensor has no attribute \u0026ldquo;backwards()\u0026rdquo; \u0026hellip;\n\u0026hellip;.\n\u0026hellip;..\n\u0026hellip;\u0026hellip;\nWHAT DO YOU MEAN TENSOR HAS NO ATTRIBUTE BACKWARDS!\nTHE THING HAS A DIRECT LINE OF COMPUTATIONAL BACK TO THE PI NETWORK!\nugh\n* ctrl+c, ctrl+v, enter, click stackoverflow *\nwait\u0026hellip; no\n* checks torch documentation *\nno no no no no\n* changes call from loss.backwards() to loss.backward() *\noh god.\n* switches tmux windows and runs the vpg file *\n* it starts learning, and learning fast *\nYO KJHGFAKJSDL HFKLSDHFJESIOUEARH ARE YOU F***ING SERIOSANJDKSHF SDAEJFGIOUWERHTWEHAFJSDKJHF KJAHFJSEK\n* happiness *\nIt is good to remember that you are and have the capacity to be a real idiot \u0026ndash; it is useful to assume this is the true State as it keeps you from being to arrogant and in the pursuit of knowledge.\nIt is also good, perhaps better, to remember that if you take the time to suffer voluntarily, doing something challenging, you are awesome.\n","date":"9 October 2022","permalink":"/napkins/suffervoluntarily/","section":"Napkins","summary":"​\nContext # I have spent the last few weeks immersing myself in the Policy Optimization Literature, within the larger field of Reinforcement Learning. This branch of Machine Learning has always been my \u0026ldquo;fancy\u0026rdquo;, of the main fields in ML, RL is the most \u0026ldquo;gangster\u0026rdquo;.","title":"Why Voluntary Suffering is Worth it"},{"content":"​\nSimply Put # Factor Analysis refers to statistical methods that reduce Variables in a Dataset to a smaller number of Factors, through Linear Combinations of Correlated Variables or with other dimensionality reduction techniques. It sees most of its use in traditional Statistics.\nThere are a few types of Factor Analysis methods:\nExploratory Factor Analysis (EFA): make no a priori assumptions about what Variables will decompose into what factors (let the data tell you what combinations of Variables will make good Factors) reduce the number of input features Confirmatory Factor Analysis (CFA): looks to test a hypothesis on Actual Variables (assuming that some combination of Variables X \u0026amp; B decompose nicely into Factor x̄) Principal Factor Analysis (PFA): aims to get the lowest number of Factors that adequately (user needs to define what adequate is) describes the Variables, this is what most jump to (in ML) when thinking about FA at large. (reduce the number of input features) These statistical folks differentiate between Factor Analysis and Factor Extraction - basically they hold the idea that a Factor Analysis is a larger-scale operation for examining relationships between features and Factor Extraction is a part of a Factor Analysis. PCA and other Correlation-Based algorithms constitute the Toolkit for Factor Extraction.\nPCA Vs. FA # The main difference between EFA and PCA is a bit of a Definitional or Philosophical one, FA assumes that there are Latent Factors waiting to be uncovered (whether we believe they are a specific combination of Variables or make no such assumption) whereas PCA just determines what Factors explain the variance in the data matrix, not at all making the kind of assumptions that FA does and much more of a method. (technical differences between individual algorithms are non-sensical, since PCA is a method for deriving Factors and therefore a part of the toolkit of Factor Analysis, for debate on this check out the wiki.\n​\nMore Info # https://www.ml-science.com/factor-analysis https://www.geeksforgeeks.org/introduction-to-factor-analytics/ ​\n","date":"14 September 2022","permalink":"/napkins/factoranalysis/","section":"Napkins","summary":"​\nSimply Put # Factor Analysis refers to statistical methods that reduce Variables in a Dataset to a smaller number of Factors, through Linear Combinations of Correlated Variables or with other dimensionality reduction techniques.","title":"Factor Analysis"},{"content":"​\nCanonically, Businesses seem to separate their internal functions product functions into 2 distinct categories. The first grouping contains things that will affect the bottom line in 5 minutes, 2 weeks, 3 months or up to 5 years, a clearly defined temporal window.The second group is one that focuses on moonshot-y projects that may or may not change the trajectory of the Business, their industry or perhaps the world at large.\nTerms we may all be familiar with that describe these two groupings are;\nProduction Research \u0026amp; Development Separating these two functions has let organizations keep the head-in-the-cloud/lofy types away from the clutches of the organizational processes that actually get the job done for corporations. This frees up the resources in these folks heads and in the organization to be able to pursue objectives that would be out of question or perhaps even ridiculous for a purely production focused system/team.\nThe separation of powers (if you will allow me the phrasing) ultimately lets the organization play to the strengths of these two rather different ends of the work spectrum and is a separation we see for Entities like Facebook/Meta with FAIR being separated from production AI development, or Google with their Brain division being distinct from their primary engineering effort. Companies that are not large enough to run both of these functions internally seem to then focus on one or the other and provide the best they can within one paradigm, take tenstorrent as an example of R\u0026amp;D and ngrok as an example of Production. Upon inspection it rather makes sense, you need to bring home a win somewhere and if you are resource constrained your best bet is to go all in on the thing you reckon you can achieve (place all your eggs in the most plausible basket). On the other hand if you have resources (and talent) you might as well cast a wider net and try to compete in many different dimensions, hoping that a few of the things that your net catches are awesome and not just more unnecessary bugs.\nThese paradigms also have fundamental differences in the inputs \u0026amp; outputs they work with. R\u0026amp;D being a resource intensive endeavor that is a bit more of a risky investment, in that it may or may not pay off \u0026ndash; and Production being about using as few resources as possible, generally prioritizing efficiency and execution over innovation. These two objectives need to be worked towards and instead of having them exist side-by-side, in the same Area of Operation, they get segregated into bins and can work on their products more independently than if they were a single unit.\nThis mechanism of thinking seems to work well in the competitive landscape of Business \u0026ndash; and is an abstraction that makes sense to bring over to your personal life.\n​\nInternal Separations of Work # Similar to the work that is done by an Organization, an Individual also does things that fall under these two categories (more or less depending on the Individual, their Work and their Interests). We can swap out the actual names of divisions at IBM for terms more closely related to what we do each day (that are roughly analagous to the Biz terms)\nProductivity Research Productivity for the Individual basically encompasses all of the items on your checklist. Tasks that are accompanied by or exist as clearly defined bullet points are tasks conducive to being on a Checklist. Being productive is easy (if your life is in order and you know how to keep things ordered so that you are in a position to be productive), all you need to do is taxonomize your tasks clearly and concisely and then go about checking things off, if there is ambiguity then do some digging and refining until you have action items clear enough to go on a checklist. Production and Productivity are all about being able to Operate and Execute on established Objectives within some Rules of Engagement and with some Assets.\nResearch is a bit more tricky, it is much more time intensive as the reason why you are endeavoring to do this work is because you do not know what you are doing. Research leads to being able to \u0026ldquo;productionize\u0026rdquo; things and this phrase is what you will hear in organizations when things come into favor or the cards line up for some interesting developments to be integrated into products or services. I would also go as far as to say that Research is much more painful, it requires more compute in the same way solving abstract math problems is more resource intensive that editing your website\u0026rsquo;s CSS (although the checklist item for one is much longer than the other, the checklist does not really grasp the challenge within the understanding of concepts). Research is all about doing non-trivial things that do not have an explicit payoff. The lessons you learn in the R\u0026amp;D phase of a topic, project, domain, etc. may pave the way to productionizing those lessons or to being able to accomplish more within checklists, but that is not known a priori and it is only after doing the voluntary suffering of learning something hard that you may find that there is no direct application of the lessons that were just learned.\nSeparating these two or at least understanding that the Tasks you need to take on in order to win (in life) fall into these two broad categories let\u0026rsquo;s you better plan how to distribute resources to be successful within domains.\n​\n","date":"31 August 2022","permalink":"/napkins/productionvsrnd/","section":"Napkins","summary":"​\nCanonically, Businesses seem to separate their internal functions product functions into 2 distinct categories. The first grouping contains things that will affect the bottom line in 5 minutes, 2 weeks, 3 months or up to 5 years, a clearly defined temporal window.","title":"Production Vs. Research"},{"content":"​\n​\nSpoiler; the ridiculously good board is the HHKB2 Professional Hybrid or your pick of Happy Hacking Keyboard\u0026rsquo;s product line.\nIf specificity in specifications or a keyboard enthusiast-esque review is more your thing, this post from Material Journal is what pushed me over the edge to cough up the somewhat aggregious amount of cash that one of these boards will run you. Something around ~$240 USD as of August of 2022.\nOne Potential Take # A fair intial reaction to that price point is \u0026ldquo;Yikes\u0026rdquo;. For An HHKB, typical cost efficiency is not its forte, per se.\nKeyboards are the interfaces to your digital tools, most people think of their Keyboards as being cheap pieces of plastic that allow them to do \u0026ldquo;stuff\u0026rdquo; on a computer. That is reasonable one way of thinking about this interface, but in that perspective there is less room for respect for your tools and less sentimentality for them. From this framework the price point is non-senscial, but if you take the stance proposed by the mind behind this line of Keyboards, the mind of Dr. Eiiti Wada then what seems ridiculous becomes plausible or even preferable. (Brilliant way to sell some plastic!)\nWada-san used this quip as an analogy for why we should deeply care about the interfaces to technology:\n\u0026ldquo;Cowboys in the western United States leave their horses when they die. But never leave their saddles, regardless of how long they need to walk in the desert. Saddles are interfaces that are deeply adapted to our bodies whereas horses are consumable items. It should not be forgotten that computers are consumables nowadays, but keyboards are interfaces that we can use through our lives.\u0026rdquo; Technology changes, the underlying hardware evolves, but the layout of the keyboards don\u0026rsquo;t and therefore the way you interact with the computer doesn\u0026rsquo;t change! This applies at different levels of abstraction and certainly there are many innovations to be had at those different levels (i.e. why have physical monitors on a desk when you can have arbitrarily many monitors in VR?)\nYet even with these potential innovations, the physical keyboard is a tool that remains and has cemented itself as a brilliant mechanism for doing stuff \u0026ndash; it is a tool that pre-dates the Eras of Compute (typewriters) and one that works.\nSo if the thing that you use to do stuff is in large part unchanged by the innovations of the stuff, you should make sure you have a good thing to do stuff with!\nA Specific Tool # As in the above, the layout and aesthetic of this keyboard look, like, the 90s \u0026ndash; or like, even older\u0026hellip;\nBut as we have established, the innovations of interfaces are indepdendent from the interfaces of hardware. This interface happens to kick \u0026ldquo;keisters\u0026rdquo; \u0026ndash; so it being seemingly antiquated is actually a sign of something special, it hasn\u0026rsquo;t been killed off by the constant stream of innovations yet. Why might that be?\nLayout is Superb: you might think at first glance of this board that someone tried to make something symmetrical and failed ever so slightly \u0026ndash; but Wada-san, the UNIX folks and Apple Teams have something non-trivial in this design they somewhat share for a keyboard. For the programmer, professional writer or really anyone that wants to maximize their productivity on a Computer \u0026ndash; you will love this. If, on the other hand a Computer in your mind is effectively a boot-loader for Google Chrome \u0026ndash; consider purchasing a tablet? (why are you even here?) Arrow Keys are located right in the middle of the special characters on the right (front of the board has glyphs to show what each key does if you press the \u0026ldquo;Fn\u0026rdquo; key on the far right side) and after getting over the learning curve, HOLY MOLY DO THEY WORK! You do not have to move your hand all over the 7 Seas and Great Kingdoms to move a cursor two fields/characters over, your hands can exist in between the spaces of VIM-bindings and Conventional Keys infinitely more seamlessly. Caps Lock at it\u0026rsquo;s regular location on the far left is criminal, a sentiment you will not understand until you feel the control key in that place (JUST HOLD SHIFT FOR CAPITAL TEXT ANYWAY!) \u0026ndash; our getting stuck with the caps lock key in that location is likely a byproduct of the typewriter. In Closing # The reason for using this keyboard is similar to the essence of the statement; \u0026ldquo;Who needs Neuralink when you have Vim.\u0026rdquo; There may be new innovations or technologies that have the potential to make things better, but if they don\u0026rsquo;t beat out the classics, should you adopt them? Not in any reasonable frame of mind, no. If it ain\u0026rsquo;t broke, don\u0026rsquo;t fix it.\n​\nIf all of the above propaganda was not sufficient for you to consider purchasing one of these boards, check out the sound of the topre switch \u0026ndash; that thock will do you in.\nPS. I am not advocating that you do away with Bluetooth and only have a Wired connection to the internet, you should accept changes that are useful but make sure that the choice is a conscious one wherein you understand what features are presented and then evaluate their utility before incorporating or discarding them. (my specific HHKB2 has a few bells and whistles that are only made possible via bluetooth and USB-C connectivity) PPS. If you close your eyes to complete a line of code or a word that you are misspelling, get this thing ASAP ​\n","date":"14 August 2022","permalink":"/napkins/thelastkeyboard/","section":"Napkins","summary":"​\n​\nSpoiler; the ridiculously good board is the HHKB2 Professional Hybrid or your pick of Happy Hacking Keyboard\u0026rsquo;s product line.\nIf specificity in specifications or a keyboard enthusiast-esque review is more your thing, this post from Material Journal is what pushed me over the edge to cough up the somewhat aggregious amount of cash that one of these boards will run you.","title":"The Last Keyboard You Should Buy"},{"content":"​ Trends and Fashions are effectively tides of widespread popularity in the way we dress but also, perhaps more importantly, in the thoughts we express and hold. At any given time the thing that is \u0026ldquo;in\u0026rdquo; is the thing that, let\u0026rsquo;s say, the \u0026ldquo;cool kids\u0026rdquo; are doing \u0026ndash; be it bell-bottom jeans, skinny jeans, eating the rich, or what have you. The changes in these Fashion Trends reflect popular culture in that they are the generally accepted principles for which a majority of people operate within \u0026ndash; holes in shirts = drip (if you live in 2016).\nWhen a New Trend, a \u0026ldquo;Bossa Nova\u0026rdquo; if you will, arises, it is worth taking a quick look at it. There are always inumerable ways in which we can fail and not know things that we do not know. Any chance to expand the perimeter of our ignorance by increasing the area of our understanding is a chance worth taking. If a new and better solution is being provided to some problem, then huzzah! We have gotten a bit more good. If not then at least we understand that another local optima has been discovered and we can act accordingly. That is great for generally open minded people that consider things seriously, but \u0026ldquo;better\u0026rdquo; is more often than not, not the metric by which people adopt new Fashions, what comes into and out of fashion seems to be; rather arbitrary or hype driven. (things that do not actually improve upon the prior state-of-the-art)\nSo why then follow a system that does not have good metrics in it\u0026rsquo;s targets? Maybe don\u0026rsquo;t.\nTake a bit of time to figure out what it is you like wrt. all of the Fashions you find yourself interested in; Clothing, Technology, Philosophy, etc. kNN is a great baseline but if we want to learn something new or arrive at conclusions that do not already exist, we need a different mechanism than the popular vote.\n​\nWhy have a Usual Fit? # Uniforms are kind of good, yes you do not want to be batched in with folks whom you do not agree with or like \u0026ndash; as might be the case within a school system. But to have thought about your own fashion-sense, to approximate something like your current solution for it and then to embody that Aesthetic actually looks really good. There is a certain respect that gets added to life when you consider things seriously, it shows in your physical appearance but also comes through in other ways. (like your code, slide decks, driving style, and the way in which you walk) That is brilliant to have, not for the sake of getting respect from others but because you start to respect yourself, which is one of the primary goals you should consider working towards if you wish to have a meaningful and productive life. Here are a few more reasons;\nIt\u0026rsquo;s Showtime: the show time effect is the effect experienced by those folks who get into costume to then go on stage. The ritual of donning your gear for a particular job; the NVGs for Special Forces, the Makeup for the Broadway Star or the Suit for a Corporate Executive. Simply the act of getting ready to do something helps you prepare for it and having your own Uniform builds that state of mind that you return to whenever you Don your gear. (I cannot find the link to the initial article but this point holds anecdotally)\nDirection Looks Good: Being disheveled or not put together due to negligence or inconsideration does not feel good any more than it looks good, you should not aim to be an Instagram Model 24/7 but you should also not live life entirely hapazardly without respect for your well being. Figuring out what works for you (a clean white t-shirt \u0026amp; jeans, a suit, just underwear, etc.) and then sticking to it looks good \u0026ndash; if you choose untidiness then own it, but making that directed decision looks great.\nSimplicity: Now you should think critically about how you want to live your life and with what gear, but you do not want to necessarily spend too much brain compute on figuring out how to get dressed (it is like reusing code, you have already solved this). Having a usual fit simplifies that process and opens up RAM for solving AGI, determining how you will live your life in a manner that you will not regret and enjoying leaves when a breeze rustles them.\nWhat then is Real Fashion? # If the widely accepted fashion is something like a kNN vote across purchases of clothing or paying of attention to ideas, that many people opt into without any thought of a possible alternative \u0026ndash; we may refer to this as an involuntary or unwitting fashion. Real Fashion might then be the thing which you choose to represent with your ideas and clothing after surveying what is available and then picking what fits you. This looks good because it is authentic and people, particularly you, deserve to live as their most authentic self.\nAuthenticity looks Good because it is Good.\n​\n","date":"8 July 2022","permalink":"/napkins/personalaesthetics/","section":"Napkins","summary":"​ Trends and Fashions are effectively tides of widespread popularity in the way we dress but also, perhaps more importantly, in the thoughts we express and hold. At any given time the thing that is \u0026ldquo;in\u0026rdquo; is the thing that, let\u0026rsquo;s say, the \u0026ldquo;cool kids\u0026rdquo; are doing \u0026ndash; be it bell-bottom jeans, skinny jeans, eating the rich, or what have you.","title":"The Real High-Fashion"},{"content":"","date":"8 June 2022","permalink":"/series/ai-writing/","section":"Series","summary":"","title":"AI Writing"},{"content":"​\nIntelligence might be thought of as the ability to compress information. Learning then is being able to find useful compressions of larger concepts that can be queried or accessed in an efficent way. What learning about something feels like is a sort of grinding proccess of trying to find a representation of the concept that works for the way our Brain is wired and for the reason which we are attempting to understand this concept. What I find rather interesting about learning and the thoughts that arise whilst trying to learn, is the place your mind goes in between the \u0026ldquo;first look\u0026rdquo; and the \u0026ldquo;aha!\u0026rdquo; moments. Autoencoders seem to be one way for computers to form these connections, boiling down the original data they are given into a useful compression.\nThe Godfather of Artificial Intelligence, Geoffrey Hinton is infamous for his colorful intuitions that describe phenomena in ways that just click. This has two effects;\nit makes learning fun (and therefore concepts are sticky) the understanding attained through a rich intuition leads to richer understanding. One brilliant example of this style is presented in this lecture- https://youtu.be/zl99IZvW7rE with the particularly pertinent bit running from about 16:20 to 16:50. (this way of spitting facts was moving enough for me to write this post, so strong intuitions either from first principles or by analogy are brilliant)\n​ ​\nThe jist of the intuition:\nEncoders compress real world observations into a thought Decoders expand thoughts into real world data (i.e. if you see cat in an image the decompression of the representation of cat could be writing the word “cat” or saying “that is a cat”) Thoughts = Latent Representations Autoencoders, whilst dealing with multi-modal datasets (e.g. captioning images) are effectively generating thoughts about what they see and translating that into a different real-world expression of the same concept (see this image from this repo) The romance behind the intuition:\nThe “Latent Representation” that an Encoder creates works out to function similarly to the way we have thoughts — thoughts are not fully described if one tries to express their meaning in real-world data like speaking or writing. (i.e. thoughts are encapsulations of concepts at a lower level than real-world data like language or images which are much more rich, not as compressed) A romantic quote attributed to the Universe’s friend Albert Einstein goes something like “To sense that behind anything that can be experienced there is a something that our minds cannot grasp, whose beauty and sublimity reaches us only indirectly… This is Religiousness.” From this one might glean a take on what ideas are — the useful bits of the input data that our Brain recieves (famously the “thought handling” or conscious part of our Brain is only able to handle about 40-50 bits of information per second, a little bit smaller than the estimated 11 million bits the whole brain can handle per second). Therefore we might come to think that Autoencoders, and by extension neural nets, are quite literally a simulation of Human thinking (as they were intended to be) and that to better understand the phenomena they pose we need to develop richer understandings of what is going on internally to us (and the nets) with more awesome intuitions.\n​\n","date":"8 June 2022","permalink":"/napkins/autoencodersthink/","section":"Napkins","summary":"​\nIntelligence might be thought of as the ability to compress information. Learning then is being able to find useful compressions of larger concepts that can be queried or accessed in an efficent way.","title":"Autoencoders are Thought Machines"},{"content":"","date":"8 June 2022","permalink":"/series/","section":"Series","summary":"","title":"Series"},{"content":"A kid from Chicago that has somehow ended up interested in building ai. I also really love and am willing to discuss at length, the topics of; Jazz, History, Philosophy, Astronomy, Intelligence, Technology and Life.\nAt the moment I am particularly interested in; the application of Reinforcement Learning to NLP, the next elegant architecture for intelligence beyond the transformer and collecting skills.\nProfessional Experience- LinkedIn\nGet in Touch- ckgresla@gmail.com\n​\nTools I Love # I was rather inspired by the romantic notion of the old internet as mentioned in this youtube video, so here are a few tools I use that bring me joy. I hope you find some use in them as well.\nAlacritty \u0026ndash; a GPU accelerated terminal emulator, can be configured for No Decorations on MacOS (resulting in a very sleek look) + is very snappy, which matters if you like to go Blazingly fast Goyo (고요) \u0026ndash; \u0026lsquo;distraction-free\u0026rsquo; writing in Vim (the superior text editor); a nice way to get colored spellcheck, line wrapping and focused writing out of the best text-editor, Goyo is Korean and roughly translates to \u0026ldquo;to do\u0026rdquo; Hugo \u0026ndash; a brilliant framework for setting up a website; written in Go, is very fast and takes a sensical approach to development (I recommend hacking on the blowfish theme, made by Nuno Coracao, this theme may look slightly familiar ;]) Things3 \u0026ndash; yes it exists only for the Apple Ecosystem, but it has a nearly perfect handle on the abstraction of Task Management (and don\u0026rsquo;t abstractions govern the usefulness of software?) Magnet \u0026ndash; I use this on my main machine, a MacBook, and continue to use it because I really enjoy the bindings. Some other window managers for MacOS I would like to check out/recommend are Yabai and Rectangle HHKB2 \u0026ndash; this thing is absolutely awesome ​\nQuirks # People seem to be divided on learning about other people\u0026rsquo;s intricacies, odd features and characteristics \u0026ndash; some could care less about the stuff that makes you, you, whereas others love to learn about the fine points that comprise their fellow man. For those that like sharing quirks, here are a few of mine:\nUse the key to space code actually insert spaces instead of \\t \u0026ndash; no more and no less than 4 characters are appropriate for a single indentation ​\nRaison d\u0026rsquo;être # Life, as far as I can tell, seems to be a \u0026ldquo;pick your own adventure\u0026rdquo;. Meaning is then something we get/have to define for ourselves. Here are a few items from the current iteration of my Raison d\u0026rsquo;être.\nLearn about Intelligence by Building It Be Serious, without taking Myself too Seriously Expand the Perimeter of my Ignorance by increasing the Area of my Understanding Maximize long-term fun ","date":"1 January 0001","permalink":"/about/","section":"CKG","summary":"A kid from Chicago that has somehow ended up interested in building ai. I also really love and am willing to discuss at length, the topics of; Jazz, History, Philosophy, Astronomy, Intelligence, Technology and Life.","title":"About"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"I wager that when You kick the bucket, you will not be wishing you thought less critically in your life \u0026ndash; hopefully you can critically consider a few of the following and make this ride a bit more fun:\n​\nHow far could humanity get naming astrophysical systems/bodies with cool names like Jupiter, Andromeda, Mars, the Jovian System, Alpha Centauri, Oumuamua, or Earth as opposed to the “XP-11213- Ac#4cP” style of naming astronomical objects? When was the last time you thought critically about something? Given the opportunity, would you like to die on Mars? (as opposed to dying on Earth) Is there anything that you, alone, are capable of doing? What would Multi-Threaded Consciousness feel like? (given that the sort of typical consciousness you and I are familiar with is a single threaded set of experiences sorted by time). What might reality be like if our experience of it was happened in parallel? Have you inherited a will (of someone or some set of ideas) or alternatively, are there wills you have inherited but are not cognizant of? Why is the Number 7 the second best number? (42 being the answer to everything kind of cements it in the top position) How much of what you believe is propaganda, or rather how much of what you believe has been arrived at in a non-data driven fashion? What is your life’s optimization equation? In that equation how do you parameterize loss? (is regret minimization the best way to parameterize loss, or what other approaches do you think are worth considering?) What Aesthetic are you embodying/living out in your life? If you have knowingly chosen it, how did you come to make that decision? Is there a line to be drawn between life \u0026amp; non-life? Where might that line exist? Do you Take Orders, Give Orders or Get The Job Done? In the history of humanity, is the advent of civilization a hardware or software upgrade? Is modernism a “set” school of thought/era of ideas, or is the “fully fledged” integration of it still waiting to be developed? (On the successful integration of the old ways with the tools of science and rationalism, being blended together elegantly, prompted by “Seeing Like a State” by SlateStar Codex) Is writing an Essay or making a Presentation just coding a program in the English language to be compiled/executed in someone else’s brain? Remember the Taste of Water For something to be Real (or rather exist) must it then also be True? Or is it possible for something that is False to exist? Knowing what to do precisely isn’t even important, all that is required is a understanding of the “Map” and a direction to move towards Is alcohol a mechanism for regularization? (similar to say \u0026ldquo;dropout\u0026rdquo;) And meditation, spiritual experiences or mushrooms mechanisms for doing data augmentation? How many people get the chance to experience real Romance? What are the fundamental operations of consciousness? What additional good could a human-computer interface like NeuralLink provide when we already have VIM? Does building your personalized version of Arch or Configuring your Vimrc parallel the forging of a lightsaber? Do you ever feel like YOU don’t have enough RAM to Code? Or brainpower to do the work you do? If the human mind does “compression” (shrinks the size of raw data to make storing it more efficient) is that process a global one for \u0026ldquo;Homo Sapiens\u0026rdquo; or is it unique to each individual? Basically, do our brains use the same file extensions? How many “One Way — Do Not Enter” signs have we already opted to enter in the Journey on the Path of Life? How many of those one ways are ultimately positive? How many were negative? What is the viscosity of the Sun? Is it like a giant ball of magma, or closer to a ball of lightning? (It is superheated plasma after-all) In the story of your life, what is the current chapter titled? のみ 星た 言葉 の 棘 が 刺さる ~= The thorns of the words I’ve gulped down stab me — E ve, 2022 Is being vulnerable an honest thing? How many people are on the verge of tears? Our eyes give us a 2D spatial view of the world, how then do we build the 3D conception that we have? (if you have to think about this from scratch) An NPC is one who fails to Reject the Null Hypothesis When in love does the scope of your consciousness expand? Particularly regarding when two individuals become a pair? If God does/were to exist, would it have a God Complex? Does one walk away from their desk whilst a Neural Net Trains or does one sit and wait for it to finish? Linear Algebra is SEXY If you conquer your fear of death, all other fears are a few applications of chain rule away Are Bureaucracies items that you might cultivate in a Garden or Fungi that sneak their way in? — despite the fact that these entities seem to be generally disliked they still persist and if they persist, must be serving some purpose\u0026hellip; Have you ever made Eye Contact with a Painting? Is finding Intelligence a reasonable proxy for Life? What is the average time complexity for a Human to determine what they want to do in this life? How many monitors is just right? What is the difference between predicting an entire sequence of values or each sequential scalar within the sequence? Severus Snape is a Giga-Chad A Quoi Ça Sert L\u0026rsquo;amour? (What is the meaning of love?) Combinatorial flavor space is best explored with un-marinated chadol and banchan. Everyone intends to do their Best Your life is the only adventure that you will get to experience — given that understanding, is it currently the best story that you can come up with? Do as you will — the Rhythm is going to get you. Where does a writer go when they pause? (whilst writing) Do Flies think of us Humans as annoying nuisances (those suckers that bat us away) or as fun past-times (hehe bzzzt bzzt, try and hit me idiot) Do you ever notice the pools of Infinite Peace and Suffering that lay within you? What Evil possesses people to put pictures of Pythons on blog posts/docs about Python related code? Do you hear the Music? Humans typically think in an Object Oriented fashion (at a higher level than animals; accomplished via language) For some, Pathetic is the Aesthetic. What proportion of your work is moonshot stuff? What amount is housekeeping? Does your proportion suit your fancy? Languages are sets of tokens that we can learn shared embeddings of Which examples are more illustrative; what to do or what not to do? Does your Personal Library have within it, a Restricted Section? Which is more important; Work-Life Balance or Your Life\u0026rsquo;s Work? TAKANAKA! One’s level of understanding for a given Topic is proven by their ability to understand Memes about that Topic! It is okay to take short breaks No Hero’s story is complete without suffering and challenge No one is too dumb for Computer Science (s/o JomaTech) Precision does not imply or mean Accuracy. nice Always have an Objective. Age is an accessory that must be dressed correctly Should knowledge/research related objectives reside in your Taxonomy of Tasks? (or should the only thing in the daily taxonomy be the act of research itself, the topic of which can span multiple days) Programming is an embodied thought experiment Bim bom, bim bim bom bom…… ( João Gilberto’s ♥) Unicode and Character Sets, do you understand the wondrous utility they provide? (and the fiascos that prompted the creation of the utility) Write Heroic Code. Do non-trivial things that do not have an explicit payoff! Is Ruthlessness relegated to being a Malevolent trait? or might it be a Benevolent one? True Beauty is not a “conclusion” that we arrive at regarding something (through say; reasoning or a conceptual framework), rather it is something that each individual senses. One Piece will be thought of as Shakespeare in the 2400s Do you ever feel grateful for a Good Night’s Sleep? Moons seem to make up most of the livable real estate in this Universe. Programmers are Alchemists, they Transmute Algorithms into Code. You aren\u0026rsquo;t personally responsible for most Old or Bad code you find on the internet What would a Negative Standard Deviation look like \u0026ndash; if it could be defined? What exactly is going on when you “Think”? Every Plug gets Popped! With great power comes great responsibility! Sci-Fi is a great way to orient a species’ objective functions toward prosperity/thriving To debug better, think of your error logs as a troubled Patient and you as a discerning, interested and caring Psychologist Ramen, Udon or Soba? Sleep with your hands open! What is your “fidget” command in your terminal? I happen to be a ls -l kind of person Saying “Lets go lets go lets go lets go” to yourself in quick succession, with enthusiasm, really does get you into the zone You will get a lot more work done if you are at peace whilst you do it If you program, you’re in good company. Aesthetics are easy to describe but very hard to define The thrill of cracking open a sketchy preworkout Embeddings/Hidden States in Neural Networks = Thoughts in Humans Music is an \u0026lsquo;aural wallpaper\u0026rsquo; The Cards, were never yours to play. What are you willing to do with your life? Absence of Regularization doesn\u0026rsquo;t imply poor Generalization! The work is the reward. ","date":"1 January 0001","permalink":"/ponderings/","section":"CKG","summary":"I wager that when You kick the bucket, you will not be wishing you thought less critically in your life \u0026ndash; hopefully you can critically consider a few of the following and make this ride a bit more fun:","title":"Ponderings"},{"content":"","date":"1 January 0001","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"}]