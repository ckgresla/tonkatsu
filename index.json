[{"content":"","date":"3 June 2023","permalink":"/napkins/","section":"Napkins","summary":"","title":"Napkins"},{"content":"","date":"3 June 2023","permalink":"/","section":"tonkatsu.io","summary":"","title":"tonkatsu.io"},{"content":"The journey of the programmer is one of ever-humbling discovery. Along this lovely trek you will experience a multitude of paradigm shifts, each of which shattering your prior conception of programming and making you a more effective programmer. For the early-stage python programmer one such paradigm shift is the one you experience when you develop the intuition for parallel programming, which for me only came when I made use of asyncio.\nThe example problem that shifted my programming-view was a toy one, waiting for some number of seconds. Let us say we want to wait for 10 seconds. A straightforward python program for this may look as follows:\nimport time def wait(n_seconds: int): time.sleep(n_seconds) print(\u0026#34;slept for {N}\u0026#34;.format(N=n_seconds)) if __name__ == \u0026#34;__main__\u0026#34;: st = time.monotonic() wait(10) #wait for our 10 seconds et = time.monotonic() print(f\u0026#34;whole script ran in {et-st:.2f}s\u0026#34;) # Outputs slept for 10 whole script ran in 10.00s In this formulation, we do the waiting in a single function call for the specified amount of time \u0026ndash; 10 seconds. This is a fine and dandy way of waiting, but what if we wanted to wait FASTER? Well since in this case there is no dependency on how we wait for 10 seconds, only that we wait for that amount of time, we can wait concurrently.\nThis means that instead of doing all of our waiting in a single function call, wait() in the above, we may split up the \u0026ldquo;waiting\u0026rdquo; across different function calls. The following illustrates how we may split up our 10 seconds of waiting across 2 functions with asnycio:\nimport time import asyncio async def wait(n_seconds: int): await asyncio.sleep(n_seconds) print(f\u0026#34;slept for {n_seconds}\u0026#34;) async def main(): jobs = [asyncio.create_task(wait(5)) for i in range(2)] await asyncio.gather(*jobs) if __name__ == \u0026#34;__main__\u0026#34;: st = time.monotonic() asyncio.run(main()) et = time.monotonic() print(f\u0026#34;whole script ran in {et-st:.2f}s\u0026#34;) # Outputs slept for 5 slept for 5 whole script ran in 5.01s That is 10 seconds of work being done in 5! This is trivial but for the fresh pair of eyes this concept is a Universe away from what the serial programmer is familiar with. What we do instead of waiting for all 10 seconds in one function is split up the 10 seconds of waiting into \u0026ldquo;jobs\u0026rdquo; that each wait for N seconds, in this case we set each \u0026ldquo;job\u0026rdquo; to wait for 5, resulting in waiting for 10 seconds in only 5 seconds of human time.\nSetting our range to 10 and the number of seconds per job to 1 results in the following output for the script above:\n# Outputs slept for 1 slept for 1 slept for 1 slept for 1 slept for 1 slept for 1 slept for 1 slept for 1 slept for 1 slept for 1 whole script ran in 1.00s As we can see, one can wait 10 seconds in 1, very cool!\nIn practice you can use this for any \u0026ldquo;work\u0026rdquo; that is not bound by process \u0026ndash; making an HTTP request, applying a tokenizer to a chunk of text data, etc. Asyncio as a library is tailored towards parallelizing IO bound operations, which means asyncio is best suited for splitting up work that does not need to wait for other work to be done.\nRecommended Readings # Dr. Jason Brownlee, doing what he does Real Python Intro ","date":"3 June 2023","permalink":"/napkins/fasterthantime/","section":"Napkins","summary":"The journey of the programmer is one of ever-humbling discovery. Along this lovely trek you will experience a multitude of paradigm shifts, each of which shattering your prior conception of programming and making you a more effective programmer.","title":"Waiting 10 Seconds in 1"},{"content":"Anyone who has gotten their feet wet with Data Science or Classical Machine Learning has come across the concept of One-Hot Encoding. A method of representing non-ordered Categorical data as a vector of zeros and a single one. One-hot encoding is a part of the accepted canon of ML, and is a common step in pre-processing data pipelines. Recently, I had the unexpected luxury of coming across the Mastering Diverse Domains through World Models paper and in it, was introduced to Two-hot encoding, an interesting generalization of one-hot encoding to continuous values. In this work the authors use two-hot encoding as part of the Critic network\u0026rsquo;s (critic being ~equal to a reward prediction network in their Actor-Critic formulation) loss function. After normalizing rewards across domains with the Symlog transformation, they apply two-hot encoding to discretize reward signals \u0026ndash; turning what was a continuous regression problem into Softmax over a binned reward distribution. In my opinion, this simple trick is GANGSTER + worth implementing.\nOne-Hot Encoding # The typical flow for one-hot encoding looks something like this;\nWe have a categorical feature (think column of data in a Table or Excel Spreadsheet), say \u0026ldquo;Beverage\u0026rdquo; That feature has a number of unique values, like: [old fashioned, coffee, makgeolli, water, lychee juice] To more easily mathematize this data for our Linear Algebraic friends, we encode with integers, for one-hot encoding that means an unordered encoding Which boils down to, \u0026ldquo;old fashioned\u0026rdquo; is no better or worse than \u0026ldquo;lychee juice\u0026rdquo; \u0026ndash; it is just different, which means encoding these variables as 1 and 2 implies a relationship that is not technically valid (the thing encoded as 2 is \u0026ldquo;greater than\u0026rdquo; the thing encoded as 1) For this toy beverage example, a native python implementation might look something like follows:\nunique_beverages = [\u0026#34;old fashioned\u0026#34;, \u0026#34;coffee\u0026#34;, \u0026#34;makgeolli\u0026#34;, \u0026#34;water\u0026#34;, \u0026#34;lychee juice\u0026#34;] def one_hot_encode(x: str): \u0026#34;\u0026#34;\u0026#34; One-Hot Encode a beverage name according to the unique beverages set \u0026#34;\u0026#34;\u0026#34; idx = unique_beverages.index(x) encoded = [] #empty list for the vals for i in range(len(unique_beverages)): if i == idx: encoded.append(1) else: encoded.append(0) return encoded Which for makgeolli, would return the vector [0, 0, 1, 0, 0] \u0026ndash; all values being zero except for the position corresponding to our instance\u0026rsquo;s categorical value, which is one.\nTwo-Hot Encoding # To generalize one-hot encoding, we need to discretize a continuous space. Something like \u0026ldquo;tastiness\u0026rdquo; might be scored on an infinite scale \u0026ndash; mid items like lukewarm chicken soup having tastiness=0.01 and tastier items like chicken nanban having tastiness=102.3\nTo Discretize a continuous space, we bin it, here I will do equidistant bins, but there might be some value in non-equidistance (really tasty things are all one bin, but moderately tasty and tasty are two separate bins) For the sake of this example, say the space of continuous tastiness values will be split into 5 bins two_hot_bins = [-5, -1, 0, 1, 5] #5 in this toy case def two_hot_encode(x: float): \u0026#34;\u0026#34;\u0026#34; Two-Hot Encode a tastiness score, assuming a sorted list of bins \u0026#34;\u0026#34;\u0026#34; encoded = [0 for i in range(5)] # Find Lower Bin Index for our x value for i in range(len(two_hot_bins)): if (two_hot_bins[i] \u0026lt;= x) and (two_hot_bins[i+1] \u0026gt;= x): b_lower, b_upper = two_hot_bins[i], two_hot_bins[i+1] #bins encircling our continuous value bl_idx, bu_idx = i, i+1 # Calculate Distances from x to nearest bins, closer ~= higher \u0026#34;probability\u0026#34; lower_dist = x - b_lower upper_dist = b_upper - x #since negative dist total_dist = lower_dist + upper_dist lower_prob, upper_prob = lower_dist/total_dist, upper_dist/total_dist encoded[bl_idx], encoded[bu_idx] = upper_prob, lower_prob #assign closest val highest \u0026#34;prob\u0026#34; # Smaller than Smallest bin value elif two_hot_bins[0] \u0026gt; x: encoded[0] = 1 # Greater than Largest bin value elif two_hot_bins[-1] \u0026lt; x: encoded[-1] = 1 return encoded Which for a tastiness value of 0.1, would return the vector [0, 0, 0.9, 0.1, 0], for a tastiness value of 1.2 would return a rounded [0, 0, 0, 0.95, 0.049] and for the value -1231 (probably tastiness of oysters) would return [1, 0, 0, 0, 0].\nSuper Cool!\n","date":"14 April 2023","permalink":"/napkins/twohotencoding/","section":"Napkins","summary":"Anyone who has gotten their feet wet with Data Science or Classical Machine Learning has come across the concept of One-Hot Encoding. A method of representing non-ordered Categorical data as a vector of zeros and a single one.","title":"Two Hot Encodings"},{"content":"What constitutes being intelligent? Is it being able to recall facts or tidbits of information with perfect recall? Or being able to dissect the statements and logic on another to prove their inferiority? Maybe intelligence is just being able to read a stack-trace properly. But perhaps, intelligence is to be measured by the efficacy of one\u0026rsquo;s hunch.\nIf accuracy in hunches is how we will measure intelligence, as opposed to; memorization efficiency or the ability to final logical inconsistencies \u0026ndash; then the wielding of intelligence is the making of correct guesses. Guessing on the basis of information is inferring something, that is to infer is to make an educated guess \u0026ndash; the folks at Oxford\u0026rsquo;s English Dictionary phrase it as:\nto infer is to decide that something is true based on the basis of the information that is available.\nInference may not comprise all of intelligence, but making correct guesses about the world is no small part of Systems that have intelligence. For those interested in Natural or Artificial intelligence, we might wonder how inference gets implemented \u0026ndash; in the accepted canon of Logic, inferences are progressive conclusions arrived at via reasoning. In Logic, since the days of Aristotle (300 BCE), inference has been divided into deductive and inductive reasoning. Thanks to one interesting fellow in the 1800s, Charles Sanders Peirce (CSP), a third method dubbed abductive reasoning joined the fray and the three methods are frameworks of reasoning that one could use to implement intelligence. Let us explore the existing implementations of intelligence via reasoning and take a speculative foray into potential avenues for new implementations.\nOne Mad Lad # The trichotomy view of reasoning methods is attributable CSP, who was something of an American Diogenes of Logic. He lived an interesting life, starting in 1842 as the son of Benjamin Peirce (Founder of the Harvard Mathematics department) \u0026ndash; CSP was quite intellectually gifted and also did rather poorly in school (failing in most classes sans Chemistry). He lived a Diogenes-esque existence in that he decided at age 20 that he would dedicate his life to the study of Logic, a field which at the time had no money available for one to make a living conducting abstract logic research. He held true to his promise to himself and was able to pump out a whopping 92,000 pages over about 57 years and 2 marriages. His second marriage followed the 1st\u0026rsquo;s divorce by 2 days and was to a woman with at least some Romani (Gypsy) ancestry, which sadly cost him his job as a Mathematics professor at John Hopkins University. He had a falling out with his academic career and later his career as a Geodetic Surveyor (measuring/studying the Earth\u0026rsquo;s gravity via pendulums) after funding was canceled and didn\u0026rsquo;t live very cushy-ily throughout his life.\nFor this mad lad though, that wasn\u0026rsquo;t necessarily a problem, since his objective was Logic-ing and he did brilliantly within that. He also believed that clustering was the most effective solution for all classification tasks, had an odd affinity for the number 3 and distilled a lovely rendition of the scientific method into logical reasoning that we should all brush up on before attempting anything worth being called science.\nMethods of Reasoning # Before we think about the implementations of reasoning in AI, lets walk through the distinguishing features of our frameworks.\nDeductive Reasoning involves making truthful statements about \u0026ldquo;truth\u0026rdquo;. Under a deductive framework we can make \u0026ldquo;correct\u0026rdquo; statements \u0026ndash; insofar as correct means in accordance with our prior knowledge. To deductively reason is to deduce a conclusion based on the attributes of the involved objects we are reasoning about. The main example used to explain deduction is the Syllogism which is typically represented as a 3 line argument:\nAll Cats are Evil A Cat is the Supreme Leader of the World The Supreme Leader is Evil The essence of the deductive inference is taking two things you hold to be true and combining their mutual information to make a third, \u0026ldquo;true\u0026rdquo;, statement.\nInductive Reasoning involves applying information you have on hand or gained from experience to new observations. This method underpins basically all of modern machine learning \u0026amp; work in AI. To make an inductive inference, one needs to have prior information and then make a prediction based on that information. Inductive reasoning, as it relates to the malevolence of cats might look like:\n99/100 Cats I have come across are Evil I see a New Cat This New Cat is likely Evil The main idea of inductive inference is using prior knowledge to predict what may occur in the future.\nAbductive Reasoning involves coming up with a likely possible explanation for a phenomena given the information you have available to you. This is sort of a combination of deduction and induction in that you leverage your current \u0026ldquo;context\u0026rdquo; to justify a statement that you believe is \u0026ldquo;true\u0026rdquo;. One example of drawing an Abductive conclusion might be:\nThere are feathers in a birdcage with the door broken off it\u0026rsquo;s hinge There is a shallow mark on the windowsill and the window is ajar A Cat did not eat the Bird, instead the Bird freed itself The main idea of abductive inference is choosing the best possible conclusion given the current context. The conclusion chosen may contradict the likelihood of observed data or your prior beliefs about the world, but it is the best hunch of the bunch.\nReasoning in \u0026ldquo;AI\u0026rdquo; # explain how AI has evolved from deductive to inductive methods AI became regarded as a proper field in the ~1950s, a lovely mixture of ideas from the fields of; Mathematics, Psychology, Engineering \u0026amp; Computer Science and the minds of great folks like; Turing, Shannon, Minksy \u0026amp; Gödel. Early AI was mainly concerned with Deductive Reasoning, the reasoning behind this was the pioneers of the field presumed that if you could bake in a lot of knowledge about the world into a Computer then it could reason about that knowledge with Superhuman speed and efficiency \u0026ndash; making it a superhuman intelligence. One big project today that is still forging in the deductive way is Cyc, which has been spearheaded by Doug Lenat since the 1980s. Deductive systems can reason about things they know to be \u0026ldquo;true\u0026rdquo; in a superhuman fashion, so why do we not have AGI or hear much about new deductive breakthroughs in AI? The issue with deductive reasoning is fundamental to the paradigm itself. Deductive systems can only make statements about that which they already know, in other words, statements about new information are irreconcilable. Deductive reasoning relies on rules about the attributes of objects to make statements, when a new/unseen object arises or a contradictory-example is provided then our deductive system is out. The veracity of a deductive system is only as salient as the quality of the truth baked into the rules of the system by Humans, which itself will not be infallible. Trying to give a deduction-based system the \u0026ldquo;keys to it\u0026rsquo;s own knowledge base\u0026rdquo; goes poorly, since updating a single statement to be contradictory then renders all statements in the system to be fallible (one error in reasoning opens the floodgates to all errors). Reasoning deductively can be mathematically/provably sound but the truth of the statement in the real world is governed it\u0026rsquo;s priors, priors which, in the case of deductive reasoning, cannot be updated without human intervention. Today we hear very little about deductive methods, instead there is an unyielding dredge of Arxiv papers all leveraging inductive reasoning. The basis of which is learning to infer from existing data. The addition of induction to the set of AI building blocks opens the door to systems that learn over time and when we cleverly combine this framework with compute \u0026amp; the data available on the internet we can create GPT-3s, and Stable Diffusions. The caveat with Neural Networks or learning to infer based on the statistics of occurring data is threefold; one we are never certain about what the next instance will be, two we have no theory as to why the data occurs in the manner it does and three the distribution underpinning life is non-stationary. The 1st might just be a [causal inference problem])( https://blog.evjang.com/2019/03/causal-rl.html), which to solve requires more comprehensive data but then again it might not be. The second is also problematic since we do not care about the why of anything, purely inductive inference only cares about the number of positive N and negative N, taking the observations we come across as being the true ground truth. Belief in observation without contemplation can be problematic, as Bertrand Russell\u0026rsquo;s Turkey. illustrates. The third is perhaps the most perplexing of all since inductive reasoning systems in the environment of reality will always be behind, they can update themselves (a big step up from deduction) but the full solution to intelligence, it is not.\nWhere is the Abduction? # If I had to guess as to how Abduction is to be implemented, I would wager that you do something like deduction over learned hypothesis probabilities. Effectively combining the truthy-ness of statements made deductively with the update-ability of induction. Some folks have formulated abductive reasoning as a next token prediction sort of task which might be sufficient but still misses a dedicated architecture for accomplishing this specific type of reasoning. To build the Ghost in the Flask we have to at minimum match Human intelligence and Humans can have pretty good hunches. Hunches that are non-obvious or even counter intuitive to the existing information.\nAs a callback to the \u0026ldquo;Inference Game\u0026rdquo; that started this post, intelligence is not about having all relevant information or sorting through a large amount of information, it is about using leveraging the available information correctly. If you also want to find out what implemented Abduction looks like, say hi.\n​\nNotes # This post was largely inspired by Erik J. Larson\u0026rsquo;s book, \u0026ldquo; The Myth of Artificial Intelligence\u0026rdquo;, which is a phenomenal read and unique take on AI as it stands today. Despite all the cool stuff LLMs can do (as of Q1 2023) I think Larson\u0026rsquo;s points are still valid. I would wager AGI is not going to be achieved by predicting the next byte-pair with a 100 trillion parameter model. ","date":"2 April 2023","permalink":"/napkins/tripartitereasoning/","section":"Napkins","summary":"What constitutes being intelligent? Is it being able to recall facts or tidbits of information with perfect recall? Or being able to dissect the statements and logic on another to prove their inferiority?","title":"A Tripartite Framework of Reasoning"},{"content":"The notion that life is suffering, unfortunately seems to be prolific in the minds of many folks these days. In part, this notion is rooted in the idea that one\u0026rsquo;s life is going to be spent clocking in and out, at 9 and 5 with a little lunch break in between, 5 days a week for the foreseeable future. There might be a vacation every now and then \u0026ndash; but it is generally accepted there is little to look forward to outside of the monotony of the day-to-day found in work. Although it might be the case that humans are rather suited to the valleys of life and that repetition with a point is the path to improvement, it still seems as though we end up losing ourselves in an abyss of mediocrity \u0026ndash; trapped in a life spent ceaselessly pondering the question; \u0026ldquo;Is this it?\u0026rdquo;\nThat notion is kind of whack and the thought of spending one\u0026rsquo;s life marinating in quiet, dissatisfied desperation is terrifying. One method of coping with this looming abyss is an escape into the Metaverse! Or perhaps more accurately, into pastimes that occupy our attention without much in return \u0026ndash; costly pastimes. Paying for stimulation in a monotonous life with your attention at first seems like an attractive proposition, but like sugary foods or sleeping late, the attractiveness evaporates with a bit time \u0026ndash; and why should stimulation for stimulation\u0026rsquo;s sake be what we want to pursue in life and spend our time on?\nI reckon that stimulation alone in life is not what we ought to pursue, instead what we should orient ourselves to aim for is that which seems like an inescapable abyss of despair \u0026ndash; work.\nWork, and our relationship to it, comprises a large chunk of our lives. Believing that work is some terrible and necessary suffering is how an abyss of despair is permitted to fester. In some cases maybe rightly so (if what you\u0026rsquo;re doing is both unnecessary and tortuous), but in all lives it is worth examining the relationship we have with work and endeavoring to improve that relationship. Doing so, for me and I reckon also for you, will lead to; a healthy productivity, a truthful inner dialogue, taking on meaningful challenges and ultimately a relationship between your Life and Work that is satisfying and exciting.\nTo provide some common ground for us to think about Life, Work \u0026amp; Living \u0026ndash; here is a little diagram of some statements that I feel encompass large camps of beliefs about work;\nThis diagram is inspired by the ye old political compass and revolves around a few simple statements that describe the relationship you have with Work, Living and Life. I took the liberty of bootstrapping some examples, populating the quadrants with what I think are archetypes of jobs and people that we can envision, empathize with and understand. The archetypes that comprise these quadrants are also colored in accordance to the perceived opinion of the folks that make up the tropes. Although stereotypes and overgeneralizing is a departure from reality (sometimes a useful compression of reality and other times not) I think these examples provide nice road-signs for us to understand the opinions present in the mental space of Life, Work and Living.\nThis diagram presents a method for classifying opinions and as such anyone in any field determines where they belong \u0026ndash; for example, a person on Wallstreet might find themselves in the bottom left hand corner at times and a Scientist that feels extremely burnt out might drift towards the upper left hand quadrant.\nInterestingly (as I didn\u0026rsquo;t intentionally plan this), a wide swath exists between our miserable and ecstatic examples, separated by those who are rather content.\nTo figure out where you and your current opinions go, determine which two statements you agree with most and your corresponding quadrant is the one with those two statements as its borders. (i.e; being of the opinions; \u0026ldquo;I live to work\u0026rdquo; and that \u0026ldquo;life is work\u0026rdquo; would nest you in the top left hand side of the diagram \u0026ndash; alongside archetypal Farmers, Policemen and Restaurant Owners)\nAxes Explanations # Before we dive into examples of the archetypal folks, let us elaborate what we mean by the statements on our axes:\nLive to Work: Is the opinion that your Life is in service to some kind of Work, something perhaps bigger than yourself or something that you feel the need to contribute to \u0026ndash; sort of embodied by ants and their objective of protecting the colony. Living to Work might mean that your life spent in service to something. Work to Live: Here we think of Working as a means to an end (i.e; since I Work, I can Live a certain way) or Work is a sort of sacrifice I make in order to then go and Live my life. This view of Work is one of sacrifice and transactions \u0026ndash; Work is endured so that we might Live in someway. Life is Work: This mode of thinking asserts that Life is comprised only of Work, a view of the future that is rather pessimistic, nihilistic or realistic \u0026ndash; This view of work is somewhat indifferent to the type of work done, work is work regardless of what you do while you work and generally is unpleasant. Work is Life: In this mode individuals believe that their Life is the Work that they take on. That they exist in order to do that work and would somewhat happily spend their Life on the tasks and challenges that comprise the chosen work. This view is characterized by an opinionated take on Work \u0026ndash; that is for these folks, a specific type of Work is how they would like to spend their lives. Generalizations of Tropes # Here are how some of the archetypal roles find themselves in their respective quadrants:\nArtists- The Artist is a person that would forgo eating, sleeping and social interaction provided they had inspiration and the means to execute on that inspiration. Because of the rather insatiable desire to produce art in a way that expresses something perceived as profound or worthwhile these folks believe that their Work is their Life. Since they are willing to forgo what is generally assumed as \u0026ldquo;living\u0026rdquo; in order to develop their craft, these folks would also assert that they Live to Work. Chefs vs. Restaurant Owners- this one was a bit tricky, since we can draw a distinction between passionate chefs (who are very similar to, if not exactly like, artists) and discerning restaurant owners. The distinction being Chefs, who are passionate about creating and sharing, do what they do for a specific reason of wanting to do it. Restaurant Owners, although hopefully somewhat interested in what they are serving, are less interested in the specifics of the product as they are the whole picture of the business. This subtlety is why we have placed the Chefs closer towards \u0026ldquo;Work is Life\u0026rdquo; than our Restaurant Owners. These two groups are both in the \u0026ldquo;Life is Work\u0026rdquo; camp, but due to the nature of what they do they have slightly different placements in the quadrants and opinions of work. Wallstreet and the Content Salaryman- The bottom right quadrant is one where people view Work as being Life but also Work to Live \u0026ndash; this is an interesting one that I think is embodied by folks who do not necessarily care immensely about the specifics of the work they do but allow it to occupy a large portion of their life and enjoy it. Work for them however is not something they would do if they were not payed, making them distinctly different from the top half of the diagram \u0026ndash; a person in Finance or a Salaryman at some company would gladly not come in to work over the weekend if it was optional. Whereas a good Law Enforcement officer would want to assist in serving justice whether or not they were in uniform \u0026amp; the mind of a scientist doesn\u0026rsquo;t turn away from science at the end of the workday. ​\nA Different Take On Work # Work, as we have established, is generally thought of as this nasty, antithesis of fun \u0026ndash; the homework to the lively 7 year old\u0026rsquo;s video games. This view is an antagonistic one, for some situations/jobs it might be a valid perspective but in the general sense Work is not something we should fear or despise. Work is just the exertion of effort in service of some objective, a focusing of our attention and spending of our time. In this General view of \u0026ldquo;Work\u0026rdquo; there is more room to classify the things we do in Life as Work \u0026ndash; not the boring things that suck our soul away but the things we do that require attention, effort and time. In this frame of view, most of \u0026ldquo;play\u0026rdquo; is Work, certainly all of our hobbies and activities outside of the mindless ones also are Work. This at first might seem like a non-useful classification, but re-framing what we think of as Work and then looking to pursue the most attractive version of it is what will result in the best possible relationship to work in our lives. To escape the local optima of thinking of work as that scam known to many as \u0026ldquo;homework\u0026rdquo; I see two clear options:\nChange the Position- if our work is actually (and honestly) the antithesis of fun and everything we find lovely \u0026amp; important in life \u0026ndash; then your position has got to change. Finding a new career/role/job/thing to do is how we can move. Change the Perspective- if our issue with work is the way we view it, we need to update our beliefs and find the things that make our work meaningful. If we examine it with a honest and optimistic perspective, there is no shortage of brilliant things to be ecstatic about. Work can be a pleasurable and amazing part of our days. The most fulfilling aspects of life are all \u0026ldquo;work-intensive\u0026rdquo;, such as;\nHaving children Working out or Exercising Programming Relationships Mathematics Cooking Developing Skills Reading Work is not just what we do between 9am and 5pm each day. Taking this narrow view of work leaves little time to seriously pursue things that are work but are not how we earn a living. Work should instead be thought of as all our paying attention, expunging effort and dedicating of time. In this viewpoint, work is the sum total of our conscious endeavors \u0026ndash; the things we chose to spend our times on being our \u0026ldquo;Life\u0026rsquo;s Work\u0026rdquo;. If we understand the finiteness of the effort, attention and time we have \u0026ndash; should we not aim to make the most of it? Shouldn\u0026rsquo;t life be spent in pursuit of things we find meaningful, interesting and challenging? Aiming to realize these types of objectives is best accomplished by Living to Work and being amongst the top half of the diagram where we care about the work we do and view it as a fundamental and major part of our lives.\nObviously work is still challenging and hard and painful and tough and it is so much easier to pull up social media or Netflix and enter vegetable mode. The reason to choose work, or endeavor to do so is because work, consciously directed towards what you care about, will return the most in the grand scheme of things. It is the most attractive investment you have available for spending your life. The things that are hard and require a bit of effort are those that bring us the most joy and fulfillment. Fun is to be found at the edge of what you are comfortable with and capable of doing \u0026ndash; where additional Work is most fruitful.\n​\nWhat Else Would You Do? # Work, directed towards what you care about, might be the most important thing we have the opportunity to do in life. If we did not have things that we wanted to work on \u0026ndash; what is there to do? Not having challenges to overcome and goals to achieve is analogous to being deceased. Without things to work towards we have no reason to get out out of bed and there is no difference between today and 10 years from now. Without work there is not much in passively existing. Life becomes even more repetitive and dull if we neglect Work than if we actively take on Work that is meaningful to us.\nWork here is also not narrowly defined \u0026ndash; I do not mean to assert that you should be gung-ho to stamp 1,000,000 arbitrary documents by hand. Work is and should be thought of broadly, as our \u0026ldquo;Life\u0026rsquo;s Work\u0026rdquo;.\nWe are at our very best, and we are happiest, when we are fully engaged in work we enjoy on the journey toward the goal we\u0026rsquo;ve established for ourselves. It gives meaning to our time off and comfort to our sleep. It makes everything else in life so wonderful, so worthwhile.\n— Earl Nightingale\n​\nAn Ideal # Ultimately, I think it is worth working towards being in the upper right hand side of the diagram. This is a place of doing work we find meaningful and being eager to learn. Challenge here is not something that is unnecessarily avoided, it is something we can accept with a grounded attitude and even enjoy with the knowledge that we will become better at doing what we care about as a result of our trials and tribulations.\nBeing in that sub-space of possible conscious experiences where we are engrossed in work we find interesting; that \u0026ldquo;flow\u0026rdquo; state or focus or whatever you would like to dub it, this is the truest way of living. When the task at hand, the Work we are doing, envelopes us the way a child loses track of time in play \u0026ndash; that state is among, if not the, best things we have the ability to experience. As a result, we should become a friend to our work and not despise it for features that it does not have.\nBest of luck.\n​\n","date":"5 January 2023","permalink":"/napkins/lifeworkliving/","section":"Napkins","summary":"The notion that life is suffering, unfortunately seems to be prolific in the minds of many folks these days. In part, this notion is rooted in the idea that one\u0026rsquo;s life is going to be spent clocking in and out, at 9 and 5 with a little lunch break in between, 5 days a week for the foreseeable future.","title":"Life, Work \u0026 Living"},{"content":" I have always found statistics to be pretty cool. The implications of the Central Limit Theorem (CLT) and being able to conduct hypothesis tests to make truth-y statements about the world is as phenomenal in my opinion as; something existing rather that nothing and backpropagation working as a tool to train neural networks. Statistics is one of the fundamental fields underpinning ML and DL, so it is always nice to keep those foundations strong \u0026ndash; I have always wanted to explore the difference between the Frequentist and Bayesian understandings of statistics and recently spent some time delving into the Bayesian branch. I think there are useful ideas for reasoning about the world in the Bayesian interpretation and hope you find them here.\nHistorical Background # The Bayesian school of statistics gets it\u0026rsquo;s name from Thomas Bayes an English statistician that whipped out Bayes\u0026rsquo; Theorem at some point in his lifetime, it was presented to the Royal Society in 1763 after his death by Richard Price. The theorem was presented as a solution to the \u0026ldquo;inverse probability problem\u0026rdquo;, basically the chaps of the 1700s wanted to calculate Posterior Distributions as we do with the Bayesian Theorem today.\nBayesianism as a school of thought in the more philosophical sense around the 1950s, around the dawn of the modern computer. Bayesian methods have been intertwined with computers and computation since the get go and have been used for AI; Naïve Bayes and Bayesian Belief Networks are two methods that leverage Bayes\u0026rsquo; Theorem to operate.\nBayesians and Frequentists # Frequentist statistics is the canonical form or interpretation of statistics, it boils down to the idea that the probability of some event, is described by the frequency or rate at which that event occurs. Bayesian statistics however, represents uncertainties in information with probabilities. That might sound like mumbo jumbo so here is an example of the difference in reasoning with the classic coin flip.\nAssume we have a fair coin, for which the Probability of it landing on heads after being tossed is 50% (i.e; \\(P(H)=0.5\\) ) The Frequentists would interpret this as meaning that 50 out of 100 coin flips should be heads because we expect Heads to occur at a rate of 50%, or half the time The Bayesians would interpret this as being equally unsure of the outcome for the next coin flip, it could be Heads or Not Heads with equal likelihood For toy problems where we have this sort of frequency of events to work with there isn\u0026rsquo;t an obvious advantage to thinking like a Bayesian, but the Bayesian perspective makes far more sense when we are examining outcomes for which many observations do not exist. Say you hear an odd sound after driving through a construction area and your car veers toward one side. You want to estimate the probability of this behavior being due to a flat tire, since you never have been in this situation before you have no outcomes to use as prior proabilities \u0026ndash; meaning that a frequentist interpretation of this problem is effectively undefined. We can estimate our belief in the probability of the odd behavior being due to a flat tire in a Bayesian sense. This makes the Bayesian framework amenable to more real world problems for which many occurences is not tractable.\nProbability Formals # Probability can be thought of as an extension of Logic; extending logical reasoning from discrete space into continuous.\nLogic is all about working with absolute beliefs, things in logic are either; True or False, in Discrete states of 0 or 1. A really effective and interesting way to think of probability is that we extend our logical reasoning into \u0026ldquo;continuous space\u0026rdquo; whereas traditional logic exists only in a discrete/binary space. This lets us extend the tools of logic into areas that would have previously been undefined or non-traversable.\nFrom a Bayesian perspective; being entirely certain that an outcome will or will not occur is equivalent to traditional logic.\n1 = 100% certain that the outcome will occur, 0 = 100% certain that the outcome will not occur. This ability to reason about likelihood of outcomes gets extended in probability, where we can explicitly define the probability of an outcome without needing it to be entirely certain one way or the other. A slightly biased coin might be have outcome probabilities of P(H)=0.85 and P(T)=0.15, there is not a discrete mapping for each outcome (since always heads or always tails doesn\u0026rsquo;t exist) but we can reason about outcomes in a logical way using these probabilities and statistics.\nIn Logic we have operators for reasoning, these are \\( \\in \\lbrace AND, OR, NOT \\rbrace \\) and their descriptive natural language counterparts: Conjunction, Disjunction, Negation \u0026ndash; which when combined with True data we can reason about the world. To make the extension into the Probabilistic domain, we need to extend these operators; the mapping of Operators in Logic to their counterparts in Probability depend on whether or not the Probabilistic Operation is Independent or Dependent.\nFor Independent Probabilities; \\( AND \\mapsto P(A) * P(B) \\) \u0026ndash; (also referred to as the \u0026ldquo;product of probabilities\u0026rdquo;), often represented as \\( P(A, B) \\) in notation \\( OR \\mapsto P(A) \\ or \\ P(B) = P(A) + P(B) \\) \u0026ndash; (the probability of event A or B occuring) \\( NOT \\mapsto \\neg P(A) = 1 - P(A) ; \\) \u0026ndash; (the \u0026ldquo;¬\u0026rdquo; symbol refers to \u0026ldquo;the negation of\u0026rdquo;, in this case the negation of the Probability of A is equal to 1-P(A), effectively the probability of not A) For Dependent Probabilities; \\( AND \\mapsto P(A) * P(B | A) ; \\) \u0026ndash; this slight difference in the \\( AND \\) operator is noteworthy, as we need to account for the dependence between the variables, the product of the two events happening then becomes the probability of the event we are interested in, A, occuring. Multiplied with the probability of B occuring, GIVEN that A has already occured. (in the independent scenario, there is no conditioning so we can just multiply the probabilities for A and B, technically we do the same thing as the dependent setting but since there is no mutual inclusitivity/dependence we just multiply by the probability of B). \\( OR \\mapsto P(A) \\ or \\ P(B) = P(A) + P(B) - P(A, B) \\) \u0026ndash; the subtraction of the \\( P(A, B) \\) term is the only change from the dependent variant, the reason for it is that we have co-occuring variables, because they are dependent on one another we need to factor in the probability of A and B occuring when we want to calculate ther probability of either A or B occuring. the not operation remains the same we use this when dealing with a single variable so it doesn\u0026rsquo;t require factoring any dependence into the definition Most of reality involves working with Dependent probabilities (mutually inclusive) and Independent Probabilities (mutually exclusive) can be thought of as special cases of the Dependent counterparts (since the formulas for these are simplified from the dependent definition). We use these methods of combining probabilities to extend logic into the probabilistic domain.\nBreakdown of Bayes Theorem # Bayes Theorem is a tool for reversing conditional probabilities, that is given the probability of an observation given a belief, \\( P(Observation|Belief) \\) we can quantify our strength in believing the belief, given the observation ( \\( P(Belief | Observation) \\) ). This gets formulated frequently in the world as \\( P(X | y)\\) wherein; \\( X=data \\) and \\( y=label \\). This formulation corresponds to estimating the likelihood of a single instance of data being from class \\( y \\) when conditioned on the observations associated with it, think Spam or Not Spam Email as our classes and the Data being the tokenized words from the email.\nBayes Theorem can be broken down as follows:\nThe Theorem \\( P(A | B) = \\frac{P(A) * P(B | A)}{P(B)} \\) The Components \\( P(A|B) \\) \u0026ndash; the Posterior Probability, thing we are interested in calculating (likelihood of observation being from class \\( y \\) \\( P(B | A) \\) \u0026ndash; the Likelihood, is our probability of an observation occuring given our Prior (given class \\(y \\) the likelihood of the observing the data) \\( P(A) \\) \u0026ndash; the Prior Probability, the probability of our Prior occuring (just the data being observed) \\( P(B) \\) \u0026ndash; the Data, this normalizes our calculation (without which we would have unnormalized probabilities) The Terms; Prior and Belief, can kind of be used interchangably, fundamentally they refer to our background information that when combined with data lets us calculate the probability of the belief being the case (say the probability of fraud occuring given some set of data, this is the prior/belief that we want to estimate a probability of occurence for given some observed data) Unormalized Posterior Comparison of Cakes # If we forgo the normalization (dividing by likelihood of data) we can still get meaningful insights from comparing two, unormalized, Bayesian Posteriors (doing just the top portion of the theorems\u0026rsquo; calculation) \u0026ndash; this is done by comparing the ratios to one another, here is an example: Our Priors: \\( P(cheesecake) = 0.9 \\) \\( P(angelcake) = 0.12 \\) Our Likelihoods: \\( P(cheesecake | GooeyTexture) = 0.8 \\) \\( P(angelcake | GooeyTexture) = 0.03 \\) Calculation of Unnormalized Posteriors; \\( P(cheesecake | GooeyTexture) * P(cheesecake) \\approx 0.72 = P(CB) \\) \u0026ndash;\u0026gt; belief in eating cheesecake \\( P(angelcake | GooeyTexture) * P(angelcake) \\approx 0.0036 = P(AB) \\) \u0026ndash;\u0026gt; belief in eating angelcake Relative Comparsion; \\( \\frac{P(CB)}{P(AB)} = 0.72/0.0036 = 200 \\) \u0026ndash; meaning the likelihood that we are eating cheesecake, given our data about texture and our priors for what cake we like to eat, is 200x more likely than the likelihood of us eating angelcake given the information. Being Less Wrong ~= Intelligence # Human brains seem to have evolved a general \u0026ldquo;sense\u0026rdquo; of likelihood. What we do in Day-to-Day life is something like Bayesian statistics, we estimate the likelihood of outcomes in order to influence decisions and all of our beliefs are conditioned on our priors of the world\u0026rsquo;s behavior. The probabilties and actual values that go into our active inference pipeline aren\u0026rsquo;t yet quantifiable in the same way we can parameterize a neural network, but we still think in roughly these terms.\nOur understanding of the world at say, timestep \\( t \\), is conditioned on our understanding of the world as we experienced it from \\(t_0 \\) -\u0026gt; \\( t_{t-1} \\) \u0026ndash; or in other words, all of our experience in the world from our first to most recent.\nBayesian Reasoning is a great way to formalize uncertainty and quantify our beliefs about the world. It has already been used to a fair extent within ML and in some AI Systems but I reckon that the Bayesian framework, as a tool for operating in the world, still has a part to play in building systems that reason how Humans do.\n","date":"30 October 2022","permalink":"/napkins/bayesianstats/","section":"Napkins","summary":"I have always found statistics to be pretty cool. The implications of the Central Limit Theorem (CLT) and being able to conduct hypothesis tests to make truth-y statements about the world is as phenomenal in my opinion as; something existing rather that nothing and backpropagation working as a tool to train neural networks.","title":"Bayesian Statistics"},{"content":"​\nThroughout my travels in Cyberspace; journeying across countless github repos, enduring several senseless Zoom meetings, delving into the depths of many package docs and interacting with Technical \u0026amp; Non-Technical folk alike, I have always wondered where the generally acceptable line between Machine Learning (ML) and Artificial Intelligence (AI) is to be drawn. It is a Friday Evening, I will be eating Ramen and will draw a somewhat arbitrary line in order to make what I believe is a meaningful (albeit nitpicky) distinction.\nI assume here that there is a meaningful difference between the two terms, one could certainly argue that ML is AI, but I think that it might be more sensical to say that AI leverages or is one application of ML.\n​\nDefinitions # To follow along with someone\u0026rsquo;s distinction between two things, you need a shared language to reason about what X \u0026amp; Y are and how they might differ or be similar;\nMachine Learning- a set of quasi-statistical, Mathematical and Computer Science-esque techniques for \u0026ldquo;learning\u0026rdquo; useful things from data Artificial Intelligence- a Man-made system that accomplishes some task rooted in the leveraging of knowledge These are not Merriam-Webster\u0026rsquo;s words but these definitions follow the jist of the respective ideas as presented in our Cornucopia of knowledge, Wikipedia; ML and AI\nAI in particular is suited to this definition as it encompasses Modern Systems like AlphaGo as well as Good Ol\u0026rsquo; Fashioned AI like Eliza \u0026ndash; also being flexible enough to include things that do not involve \u0026ldquo;learning from data\u0026rdquo; such as Static Knowledge Bases or the wizardry yet to be discovered that leads to AGI.\n​\nThe Difference # Machine Learning techniques are brilliant at learning and AI Systems are those in which we apply knowledge \u0026ndash; that knowledge can be transfered or learned but the AI system is not itself doing the learning (an aspect of it, say the Model/Controller/Head, is). Why then is this relevant?\nFor one, some of the technical folk get angry when any system that is capable of something we might call intelligent gets called AI, be it solving protein folding or becoming the world\u0026rsquo;s most diversely skilled artist. In this frame of thought, being able to use a neural network doesn\u0026rsquo;t make you intelligent \u0026ndash; which is neither fun nor sensical. Systems like AlphaFold exhibit superhuman intelligence on tasks and are also artificial, your brain can do the sum() operation to combine your representations of these two concepts.\nThe non-technical folk also get into a ruffle when simple applications of ML expose themselves, achieving 87% accuracy on classifying the likelihood of crops going sour or reducing the dimensionality of a tabular dataset are both great applications of learning, but in vaccum are not themselves acts of intelligence. For methods leveraging Machine Learning to be intelligent, they must be implemented, and the implementation, the artificial one, is what gives birth to AI.\nIt is worth noting that the model of something like GPT-3 or Stable Diffusions is basically AI. (since they can exhibit intelligence in applications out of the box and great proficency at those applications) But the models trained alone are not intelligent, it tasks usage in a downstream application for it to exhibit intelligence, up until then it has just reduced error on some data, effectively learning something useful.\nAll in all in is nitpicky to differentiate between ML and AI \u0026ndash; but I think necessary to get all the great folks on the same page. ML is a toolkit of methods for learning and AI is the application of crafted knowledge \u0026ndash; you just use backpropagation to sculpt that knowledge.\n​\n","date":"28 October 2022","permalink":"/napkins/diff-ml-ai/","section":"Napkins","summary":"​\nThroughout my travels in Cyberspace; journeying across countless github repos, enduring several senseless Zoom meetings, delving into the depths of many package docs and interacting with Technical \u0026amp; Non-Technical folk alike, I have always wondered where the generally acceptable line between Machine Learning (ML) and Artificial Intelligence (AI) is to be drawn.","title":"The Difference between ML and AI"},{"content":"​\nContext # I have spent the last few weeks immersing myself in the Policy Optimization Literature, within the larger field of Reinforcement Learning. This branch of Machine Learning has always been my \u0026ldquo;fancy\u0026rdquo;, of the main fields in ML, RL is the most \u0026ldquo;gangster\u0026rdquo;. This affinity for the field of figuring out how to create Agents that can learn things more closely to the way that humans learn is what has prompted me to wake up a little extra early each day; diving into papers and programming before the hitting the gym and before the main work day.\nThese past 2-ish weeks have been spent trying to implement the VPG, basically what was done in Sutton\u0026rsquo;s paper from 2000 with the addition of generalized advantage estimation ( see section 4) a method for reducing variance of the Policy Gradient (effectively the \u0026ldquo;error\u0026rdquo; we want to backprop to our Policy Network parameters for learning).\n​\nJust Sit With it # The math behind the Generalized Advantage Estimate (GAE) calculation isn\u0026rsquo;t all that bad, Schulman (who is just brilliant) breaks everything down nicely in his thesis, the intuition for GAE is also a nice one; basically we want to train our Policy Network based on not all of the Reward signals but only the reward signals that come from Actions that do better than expected. It doesn\u0026rsquo;t sound all that bad and the only difference from my prior implmentation of REINFORCE is just; the introduction a Value Function estimator (second network that is trained to predict reward given states) and calculating advantage estimates for backprop in the Policy Network.\nSounds trivial, right?\nIt actually is trivial! But never underestimate your ability to be an absolute nincompoop!\nThis problem really haunted me, it was one of those kinds of things where you understand it conceptually but looking at other implementations throws off your understanding and you get caught in this loop of trying to get it to work but then second guessing your understanding and reviewing the papers and math and blah blah blah. Everyone person that does difficult things occasionally finds themself in the \u0026ldquo;spinning of the wheels\u0026rdquo;, that lovely place amongst the mud, nonsense and the sense that they should stop being; [stupid, weak, a loser, dumb, lazy, etc.] and just get it done. In these times even though you do step away and let the problem marinate you just gotta sit with the problem. Progress is still made even if code/whatever your metric of performance isn\u0026rsquo;t being increased. The mere act of enduring the muck increases your skills. Being stubborn and hitting your head against the wall or continously attempting to climb the plateau after falling is the way through. It sucks yea, and all that comes with sucking generally sucks; but the thing to remember is that it\u0026rsquo;ll pass, and with each blow you take, you also get STRONGER.\nSo just sit with the problem, don\u0026rsquo;t run the same function wondering why it doesn\u0026rsquo;t work (or at least try to refrain from doing it \u0026lt; 3 times before thinking about the error) \u0026ndash; the answer will come in due time, you can think of it as your Unconscious Self updating the gradient.\n​\nLots of Ecstatic Yelling \u0026amp; Some Jumping # After weeks of this debauchery, I sat down this lovely Autumn Sunday to do battle yet again with this. I spent the better part of an afternoon implementing GAE in my VPG with no luck.\nI tried the discounted cumsum trick, grads didn\u0026rsquo;t get tracked correctly I tried to do the compute with vectors as opposed to elementwise, issues with the discount cumsum calculation I tried to do everything elementwise, Tensor has no attribute \u0026ldquo;backwards()\u0026rdquo; \u0026hellip;\n\u0026hellip;.\n\u0026hellip;..\n\u0026hellip;\u0026hellip;\nWHAT DO YOU MEAN TENSOR HAS NO ATTRIBUTE BACKWARDS!\nTHE THING HAS A DIRECT LINE OF COMPUTATIONAL BACK TO THE PI NETWORK!\nugh\n* ctrl+c, ctrl+v, enter, click stackoverflow *\nwait\u0026hellip; no\n* checks torch documentation *\nno no no no no\n* changes call from loss.backwards() to loss.backward() *\noh god.\n* switches tmux windows and runs the vpg file *\n* it starts learning, and learning fast *\nYO KJHGFAKJSDL HFKLSDHFJESIOUEARH ARE YOU F***ING SERIOSANJDKSHF SDAEJFGIOUWERHTWEHAFJSDKJHF KJAHFJSEK\n* happiness *\nIt is good to remember that you are and have the capacity to be a real idiot \u0026ndash; it is useful to assume this is the true State as it keeps you from being to arrogant and in the pursuit of knowledge.\nIt is also good, perhaps better, to remember that if you take the time to suffer voluntarily, doing something challenging, you are awesome.\n","date":"9 October 2022","permalink":"/napkins/suffervoluntarily/","section":"Napkins","summary":"​\nContext # I have spent the last few weeks immersing myself in the Policy Optimization Literature, within the larger field of Reinforcement Learning. This branch of Machine Learning has always been my \u0026ldquo;fancy\u0026rdquo;, of the main fields in ML, RL is the most \u0026ldquo;gangster\u0026rdquo;.","title":"Why Voluntary Suffering is Worth it"},{"content":"​\nSimply Put # Factor Analysis refers to statistical methods that reduce Variables in a Dataset to a smaller number of Factors, through Linear Combinations of Correlated Variables or with other dimensionality reduction techniques. It sees most of its use in traditional Statistics.\nThere are a few types of Factor Analysis methods:\nExploratory Factor Analysis (EFA): make no a priori assumptions about what Variables will decompose into what factors (let the data tell you what combinations of Variables will make good Factors) reduce the number of input features Confirmatory Factor Analysis (CFA): looks to test a hypothesis on Actual Variables (assuming that some combination of Variables X \u0026amp; B decompose nicely into Factor x̄) Principal Factor Analysis (PFA): aims to get the lowest number of Factors that adequately (user needs to define what adequate is) describes the Variables, this is what most jump to (in ML) when thinking about FA at large. (reduce the number of input features) These statistical folks differentiate between Factor Analysis and Factor Extraction - basically they hold the idea that a Factor Analysis is a larger-scale operation for examining relationships between features and Factor Extraction is a part of a Factor Analysis. PCA and other Correlation-Based algorithms constitute the Toolkit for Factor Extraction.\nPCA Vs. FA # The main difference between EFA and PCA is a bit of a Definitional or Philosophical one, FA assumes that there are Latent Factors waiting to be uncovered (whether we believe they are a specific combination of Variables or make no such assumption) whereas PCA just determines what Factors explain the variance in the data matrix, not at all making the kind of assumptions that FA does and much more of a method. (technical differences between individual algorithms are non-sensical, since PCA is a method for deriving Factors and therefore a part of the toolkit of Factor Analysis, for debate on this check out the wiki.\n​\nMore Info # https://www.ml-science.com/factor-analysis https://www.geeksforgeeks.org/introduction-to-factor-analytics/ ​\n","date":"14 September 2022","permalink":"/napkins/factoranalysis/","section":"Napkins","summary":"​\nSimply Put # Factor Analysis refers to statistical methods that reduce Variables in a Dataset to a smaller number of Factors, through Linear Combinations of Correlated Variables or with other dimensionality reduction techniques.","title":"Factor Analysis"},{"content":"​\nCanonically, Businesses seem to separate their internal functions product functions into 2 distinct categories. The first grouping contains things that will affect the bottom line in 5 minutes, 2 weeks, 3 months or up to 5 years, a clearly defined temporal window.The second group is one that focuses on moonshot-y projects that may or may not change the trajectory of the Business, their industry or perhaps the world at large.\nTerms we may all be familiar with that describe these two groupings are;\nProduction Research \u0026amp; Development Separating these two functions has let organizations keep the head-in-the-cloud/lofy types away from the clutches of the organizational processes that actually get the job done for corporations. This frees up the resources in these folks heads and in the organization to be able to pursue objectives that would be out of question or perhaps even ridiculous for a purely production focused system/team.\nThe separation of powers (if you will allow me the phrasing) ultimately lets the organization play to the strengths of these two rather different ends of the work spectrum and is a separation we see for Entities like Facebook/Meta with FAIR being separated from production AI development, or Google with their Brain division being distinct from their primary engineering effort. Companies that are not large enough to run both of these functions internally seem to then focus on one or the other and provide the best they can within one paradigm, take tenstorrent as an example of R\u0026amp;D and ngrok as an example of Production. Upon inspection it rather makes sense, you need to bring home a win somewhere and if you are resource constrained your best bet is to go all in on the thing you reckon you can achieve (place all your eggs in the most plausible basket). On the other hand if you have resources (and talent) you might as well cast a wider net and try to compete in many different dimensions, hoping that a few of the things that your net catches are awesome and not just more unnecessary bugs.\nThese paradigms also have fundamental differences in the inputs \u0026amp; outputs they work with. R\u0026amp;D being a resource intensive endeavor that is a bit more of a risky investment, in that it may or may not pay off \u0026ndash; and Production being about using as few resources as possible, generally prioritizing efficiency and execution over innovation. These two objectives need to be worked towards and instead of having them exist side-by-side, in the same Area of Operation, they get segregated into bins and can work on their products more independently than if they were a single unit.\nThis mechanism of thinking seems to work well in the competitive landscape of Business \u0026ndash; and is an abstraction that makes sense to bring over to your personal life.\n​\nInternal Separations of Work # Similar to the work that is done by an Organization, an Individual also does things that fall under these two categories (more or less depending on the Individual, their Work and their Interests). We can swap out the actual names of divisions at IBM for terms more closely related to what we do each day (that are roughly analagous to the Biz terms)\nProductivity Research Productivity for the Individual basically encompasses all of the items on your checklist. Tasks that are accompanied by or exist as clearly defined bullet points are tasks conducive to being on a Checklist. Being productive is easy (if your life is in order and you know how to keep things ordered so that you are in a position to be productive), all you need to do is taxonomize your tasks clearly and concisely and then go about checking things off, if there is ambiguity then do some digging and refining until you have action items clear enough to go on a checklist. Production and Productivity are all about being able to Operate and Execute on established Objectives within some Rules of Engagement and with some Assets.\nResearch is a bit more tricky, it is much more time intensive as the reason why you are endeavoring to do this work is because you do not know what you are doing. Research leads to being able to \u0026ldquo;productionize\u0026rdquo; things and this phrase is what you will hear in organizations when things come into favor or the cards line up for some interesting developments to be integrated into products or services. I would also go as far as to say that Research is much more painful, it requires more compute in the same way solving abstract math problems is more resource intensive that editing your website\u0026rsquo;s CSS (although the checklist item for one is much longer than the other, the checklist does not really grasp the challenge within the understanding of concepts). Research is all about doing non-trivial things that do not have an explicit payoff. The lessons you learn in the R\u0026amp;D phase of a topic, project, domain, etc. may pave the way to productionizing those lessons or to being able to accomplish more within checklists, but that is not known a priori and it is only after doing the voluntary suffering of learning something hard that you may find that there is no direct application of the lessons that were just learned.\nSeparating these two or at least understanding that the Tasks you need to take on in order to win (in life) fall into these two broad categories let\u0026rsquo;s you better plan how to distribute resources to be successful within domains.\n​\n","date":"31 August 2022","permalink":"/napkins/productionvsrnd/","section":"Napkins","summary":"​\nCanonically, Businesses seem to separate their internal functions product functions into 2 distinct categories. The first grouping contains things that will affect the bottom line in 5 minutes, 2 weeks, 3 months or up to 5 years, a clearly defined temporal window.","title":"Production Vs. Research"},{"content":"​\n​\nSpoiler; the ridiculously good board is the HHKB2 Professional Hybrid or your pick of Happy Hacking Keyboard\u0026rsquo;s product line.\nIf specificity in specifications or a keyboard enthusiast-esque review is more your thing, this post from Material Journal is what pushed me over the edge to cough up the somewhat aggregious amount of cash that one of these boards will run you. Something around ~$240 USD as of August of 2022.\nOne Potential Take # A fair intial reaction to that price point is \u0026ldquo;Yikes\u0026rdquo;. For An HHKB, typical cost efficiency is not its forte, per se.\nKeyboards are the interfaces to your digital tools, most people think of their Keyboards as being cheap pieces of plastic that allow them to do \u0026ldquo;stuff\u0026rdquo; on a computer. That is reasonable one way of thinking about this interface, but in that perspective there is less room for respect for your tools and less sentimentality for them. From this framework the price point is non-senscial, but if you take the stance proposed by the mind behind this line of Keyboards, the mind of Dr. Eiiti Wada then what seems ridiculous becomes plausible or even preferable. (Brilliant way to sell some plastic!)\nWada-san used this quip as an analogy for why we should deeply care about the interfaces to technology:\n\u0026ldquo;Cowboys in the western United States leave their horses when they die. But never leave their saddles, regardless of how long they need to walk in the desert. Saddles are interfaces that are deeply adapted to our bodies whereas horses are consumable items. It should not be forgotten that computers are consumables nowadays, but keyboards are interfaces that we can use through our lives.\u0026rdquo; Technology changes, the underlying hardware evolves, but the layout of the keyboards don\u0026rsquo;t and therefore the way you interact with the computer doesn\u0026rsquo;t change! This applies at different levels of abstraction and certainly there are many innovations to be had at those different levels (i.e. why have physical monitors on a desk when you can have arbitrarily many monitors in VR?)\nYet even with these potential innovations, the physical keyboard is a tool that remains and has cemented itself as a brilliant mechanism for doing stuff \u0026ndash; it is a tool that pre-dates the Eras of Compute (typewriters) and one that works.\nSo if the thing that you use to do stuff is in large part unchanged by the innovations of the stuff, you should make sure you have a good thing to do stuff with!\nA Specific Tool # As in the above, the layout and aesthetic of this keyboard look, like, the 90s \u0026ndash; or like, even older\u0026hellip;\nBut as we have established, the innovations of interfaces are indepdendent from the interfaces of hardware. This interface happens to kick \u0026ldquo;keisters\u0026rdquo; \u0026ndash; so it being seemingly antiquated is actually a sign of something special, it hasn\u0026rsquo;t been killed off by the constant stream of innovations yet. Why might that be?\nLayout is Superb: you might think at first glance of this board that someone tried to make something symmetrical and failed ever so slightly \u0026ndash; but Wada-san, the UNIX folks and Apple Teams have something non-trivial in this design they somewhat share for a keyboard. For the programmer, professional writer or really anyone that wants to maximize their productivity on a Computer \u0026ndash; you will love this. If, on the other hand a Computer in your mind is effectively a boot-loader for Google Chrome \u0026ndash; consider purchasing a tablet? (why are you even here?) Arrow Keys are located right in the middle of the special characters on the right (front of the board has glyphs to show what each key does if you press the \u0026ldquo;Fn\u0026rdquo; key on the far right side) and after getting over the learning curve, HOLY MOLY DO THEY WORK! You do not have to move your hand all over the 7 Seas and Great Kingdoms to move a cursor two fields/characters over, your hands can exist in between the spaces of VIM-bindings and Conventional Keys infinitely more seamlessly. Caps Lock at it\u0026rsquo;s regular location on the far left is criminal, a sentiment you will not understand until you feel the control key in that place (JUST HOLD SHIFT FOR CAPITAL TEXT ANYWAY!) \u0026ndash; our getting stuck with the caps lock key in that location is likely a byproduct of the typewriter. In Closing # The reason for using this keyboard is similar to the essence of the statement; \u0026ldquo;Who needs Neuralink when you have Vim.\u0026rdquo; There may be new innovations or technologies that have the potential to make things better, but if they don\u0026rsquo;t beat out the classics, should you adopt them? Not in any reasonable frame of mind, no. If it ain\u0026rsquo;t broke, don\u0026rsquo;t fix it.\n​\nIf all of the above propaganda was not sufficient for you to consider purchasing one of these boards, check out the sound of the topre switch \u0026ndash; that thock will do you in.\nPS. I am not advocating that you do away with Bluetooth and only have a Wired connection to the internet, you should accept changes that are useful but make sure that the choice is a conscious one wherein you understand what features are presented and then evaluate their utility before incorporating or discarding them. (my specific HHKB2 has a few bells and whistles that are only made possible via bluetooth and USB-C connectivity) PPS. If you close your eyes to complete a line of code or a word that you are misspelling, get this thing ASAP ​\n","date":"14 August 2022","permalink":"/napkins/thelastkeyboard/","section":"Napkins","summary":"​\n​\nSpoiler; the ridiculously good board is the HHKB2 Professional Hybrid or your pick of Happy Hacking Keyboard\u0026rsquo;s product line.\nIf specificity in specifications or a keyboard enthusiast-esque review is more your thing, this post from Material Journal is what pushed me over the edge to cough up the somewhat aggregious amount of cash that one of these boards will run you.","title":"The Last Keyboard You Should Buy"},{"content":"​ Trends and Fashions are effectively tides of widespread popularity in the way we dress but also, perhaps more importantly, in the thoughts we express and hold. At any given time the thing that is \u0026ldquo;in\u0026rdquo; is the thing that, let\u0026rsquo;s say, the \u0026ldquo;cool kids\u0026rdquo; are doing \u0026ndash; be it bell-bottom jeans, skinny jeans, eating the rich, or what have you. The changes in these Fashion Trends reflect popular culture in that they are the generally accepted principles for which a majority of people operate within \u0026ndash; holes in shirts = drip (if you live in 2016).\nWhen a New Trend, a \u0026ldquo;Bossa Nova\u0026rdquo; if you will, arises, it is worth taking a quick look at it. There are always inumerable ways in which we can fail and not know things that we do not know. Any chance to expand the perimeter of our ignorance by increasing the area of our understanding is a chance worth taking. If a new and better solution is being provided to some problem, then huzzah! We have gotten a bit more good. If not then at least we understand that another local optima has been discovered and we can act accordingly. That is great for generally open minded people that consider things seriously, but \u0026ldquo;better\u0026rdquo; is more often than not, not the metric by which people adopt new Fashions, what comes into and out of fashion seems to be; rather arbitrary or hype driven. (things that do not actually improve upon the prior state-of-the-art)\nSo why then follow a system that does not have good metrics in it\u0026rsquo;s targets? Maybe don\u0026rsquo;t.\nTake a bit of time to figure out what it is you like wrt. all of the Fashions you find yourself interested in; Clothing, Technology, Philosophy, etc. kNN is a great baseline but if we want to learn something new or arrive at conclusions that do not already exist, we need a different mechanism than the popular vote.\n​\nWhy have a Usual Fit? # Uniforms are kind of good, yes you do not want to be batched in with folks whom you do not agree with or like \u0026ndash; as might be the case within a school system. But to have thought about your own fashion-sense, to approximate something like your current solution for it and then to embody that Aesthetic actually looks really good. There is a certain respect that gets added to life when you consider things seriously, it shows in your physical appearance but also comes through in other ways. (like your code, slide decks, driving style, and the way in which you walk) That is brilliant to have, not for the sake of getting respect from others but because you start to respect yourself, which is one of the primary goals you should consider working towards if you wish to have a meaningful and productive life. Here are a few more reasons;\nIt\u0026rsquo;s Showtime: the show time effect is the effect experienced by those folks who get into costume to then go on stage. The ritual of donning your gear for a particular job; the NVGs for Special Forces, the Makeup for the Broadway Star or the Suit for a Corporate Executive. Simply the act of getting ready to do something helps you prepare for it and having your own Uniform builds that state of mind that you return to whenever you Don your gear. (I cannot find the link to the initial article but this point holds anecdotally)\nDirection Looks Good: Being disheveled or not put together due to negligence or inconsideration does not feel good any more than it looks good, you should not aim to be an Instagram Model 24/7 but you should also not live life entirely hapazardly without respect for your well being. Figuring out what works for you (a clean white t-shirt \u0026amp; jeans, a suit, just underwear, etc.) and then sticking to it looks good \u0026ndash; if you choose untidiness then own it, but making that directed decision looks great.\nSimplicity: Now you should think critically about how you want to live your life and with what gear, but you do not want to necessarily spend too much brain compute on figuring out how to get dressed (it is like reusing code, you have already solved this). Having a usual fit simplifies that process and opens up RAM for solving AGI, determining how you will live your life in a manner that you will not regret and enjoying leaves when a breeze rustles them.\nWhat then is Real Fashion? # If the widely accepted fashion is something like a kNN vote across purchases of clothing or paying of attention to ideas, that many people opt into without any thought of a possible alternative \u0026ndash; we may refer to this as an involuntary or unwitting fashion. Real Fashion might then be the thing which you choose to represent with your ideas and clothing after surveying what is available and then picking what fits you. This looks good because it is authentic and people, particularly you, deserve to live as their most authentic self.\nAuthenticity looks Good because it is Good.\n​\n","date":"8 July 2022","permalink":"/napkins/personalaesthetics/","section":"Napkins","summary":"​ Trends and Fashions are effectively tides of widespread popularity in the way we dress but also, perhaps more importantly, in the thoughts we express and hold. At any given time the thing that is \u0026ldquo;in\u0026rdquo; is the thing that, let\u0026rsquo;s say, the \u0026ldquo;cool kids\u0026rdquo; are doing \u0026ndash; be it bell-bottom jeans, skinny jeans, eating the rich, or what have you.","title":"The Real High-Fashion"},{"content":"","date":"8 June 2022","permalink":"/series/ai-writing/","section":"Series","summary":"","title":"AI Writing"},{"content":"​\nIntelligence might be thought of as the ability to compress information. Learning then is being able to find useful compressions of larger concepts that can be queried or accessed in an efficent way. What learning about something feels like is a sort of grinding proccess of trying to find a representation of the concept that works for the way our Brain is wired and for the reason which we are attempting to understand this concept. What I find rather interesting about learning and the thoughts that arise whilst trying to learn, is the place your mind goes in between the \u0026ldquo;first look\u0026rdquo; and the \u0026ldquo;aha!\u0026rdquo; moments. Autoencoders seem to be one way for computers to form these connections, boiling down the original data they are given into a useful compression.\nThe Godfather of Artificial Intelligence, Geoffrey Hinton is infamous for his colorful intuitions that describe phenomena in ways that just click. This has two effects;\nit makes learning fun (and therefore concepts are sticky) the understanding attained through a rich intuition leads to richer understanding. One brilliant example of this style is presented in this lecture- https://youtu.be/zl99IZvW7rE with the particularly pertinent bit running from about 16:20 to 16:50. (this way of spitting facts was moving enough for me to write this post, so strong intuitions either from first principles or by analogy are brilliant)\n​ ​\nThe jist of the intuition:\nEncoders compress real world observations into a thought Decoders expand thoughts into real world data (i.e. if you see cat in an image the decompression of the representation of cat could be writing the word “cat” or saying “that is a cat”) Thoughts = Latent Representations Autoencoders, whilst dealing with multi-modal datasets (e.g. captioning images) are effectively generating thoughts about what they see and translating that into a different real-world expression of the same concept (see this image from this repo) The romance behind the intuition:\nThe “Latent Representation” that an Encoder creates works out to function similarly to the way we have thoughts — thoughts are not fully described if one tries to express their meaning in real-world data like speaking or writing. (i.e. thoughts are encapsulations of concepts at a lower level than real-world data like language or images which are much more rich, not as compressed) A romantic quote attributed to the Universe’s friend Albert Einstein goes something like “To sense that behind anything that can be experienced there is a something that our minds cannot grasp, whose beauty and sublimity reaches us only indirectly… This is Religiousness.” From this one might glean a take on what ideas are — the useful bits of the input data that our Brain recieves (famously the “thought handling” or conscious part of our Brain is only able to handle about 40-50 bits of information per second, a little bit smaller than the estimated 11 million bits the whole brain can handle per second). Therefore we might come to think that Autoencoders, and by extension neural nets, are quite literally a simulation of Human thinking (as they were intended to be) and that to better understand the phenomena they pose we need to develop richer understandings of what is going on internally to us (and the nets) with more awesome intuitions.\n​\n","date":"8 June 2022","permalink":"/napkins/autoencodersthink/","section":"Napkins","summary":"​\nIntelligence might be thought of as the ability to compress information. Learning then is being able to find useful compressions of larger concepts that can be queried or accessed in an efficent way.","title":"Autoencoders are Thought Machines"},{"content":"","date":"8 June 2022","permalink":"/series/","section":"Series","summary":"","title":"Series"},{"content":"This Universe is extremely kind, not only does something exist rather than nothing, our \u0026ldquo;something\u0026rdquo; contains an effectively endless cornucopia of brilliant work for us to absorb and learn from. When it comes to knowledge we have not been \u0026ldquo;skimped\u0026rdquo;, but like all worthwhile things we need to seek out the good stuff \u0026ndash; to make your search for brilliance a bit more efficient, take a peek at the following pieces I have come across and found useful. I hope you will be able to take away more and apply it well.\n​\nTitle Location Raison A Message to Garcia https://courses.csail.mit.edu/6.803/pdf/hubbard1899.pdf Are you capable of carrying the letter? The Logintaka http://catb.org/~esr/faqs/loginataka.html a dialogue between a Guru and a Newbie How To Become A Hacker http://www.catb.org/~esr/faqs/hacker-howto.html They are on to something you know The Bitter Lesson http://incompleteideas.net/IncIdeas/BitterLesson.html Just add more Data \u0026amp; Compute Poetry and Ambition https://poets.org/text/poetry-and-ambition McPoems? Oh Dear. Mozart, Writing Symphonies and Young Lawyers with Questions https://fs.blog/brain-food/october-30-2022/ Scroll to the bottom Occam\u0026rsquo;s Razor http://pespmc1.vub.ac.be/OCCAMRAZ.html As necessary, more gets messy Gunga Din https://www.poetryfoundation.org/poems/46783/gunga-din You\u0026rsquo;re a better man than I\u0026hellip; I love my wife. My wife is dead. https://lettersofnote.com/2012/02/15/i-love-my-wife-my-wife-is-dead/ @Yeobo Be Drunk https://poets.org/poem/be-drunk Wine, Poetry or Virtue - as you wish. A Mathematician\u0026rsquo;s Apology https://web.njit.edu/~akansu/PAPERS/GHHardy-AMathematiciansApology.pdf A peek into the mind of a mathematician Horatius\u0026rsquo; Last Stand https://www.goodreads.com/quotes/21898-then-out-spake-brave-horatius-the-captain-of-the-gate Is there a better way to go? Electric Meat https://matt.might.net/articles/electric-meat/ Grab a few things! ","date":"1 January 0001","permalink":"/selected_readings/","section":"tonkatsu.io","summary":"This Universe is extremely kind, not only does something exist rather than nothing, our \u0026ldquo;something\u0026rdquo; contains an effectively endless cornucopia of brilliant work for us to absorb and learn from. When it comes to knowledge we have not been \u0026ldquo;skimped\u0026rdquo;, but like all worthwhile things we need to seek out the good stuff \u0026ndash; to make your search for brilliance a bit more efficient, take a peek at the following pieces I have come across and found useful.","title":"A Selection of Readings"},{"content":" I am Workin\u0026rsquo; and enjoying this Hero Journey of life. These days this means predominantly spending my time on NLP and RL. Professionally I am a Member of the Technical Staff @ lindy.ai I do not really have a social media presence I love the following; Jazz, History, CS, Food, Nuclear Fusion, Philosophy, Cultures, Sprituallity, Astronomy, Intelligence, and Life. If you also like these topics then say hi Professional Experience- LinkedIn\nSay Hi- ckgresla at gmail dot com\n​\nTools I Love # I am inspired by the optimistic and individualistic ideas for an \u0026ldquo;Internet Evolution\u0026rdquo; that seem to have been proposed in 2000s. These ideas resurfaced in this YouTube video and in part revolve around personal recommendation via link pages/sections as a way of creating meaningful connections on the web. This section is curated list of my personal recommendations for you \u0026ndash; I hope they bring you as much, or more joy than they have brought me.\nAlacritty \u0026ndash; is a cross-platform, GPU accelerated terminal emulator. It can be configured beyond your heart\u0026rsquo;s desire (one example of this extensibility being the removal of window decorations on MacOS, very sleek) + it is extremely snappy, which matters if you like to be Blazingly fast catppuccin \u0026ndash; is at it\u0026rsquo;s simplest, a lovely pastel theme. I reckon that it goes beyond being a simple palette of colors, becoming an tasteful approach to productivity. Goyo (고요) \u0026ndash; \u0026lsquo;distraction-free\u0026rsquo; writing in Vim, a nice way to get colored spellcheck, line wrapping and a focused writing experience in the Terminal. \u0026ldquo;Goyo\u0026rdquo; is Korean and roughly translates to \u0026ldquo;to do\u0026rdquo; Hugo \u0026ndash; a brilliant framework for setting up a website; written in Go, is very fast and takes a sensible approach to developing a personal website (I recommend hacking on the blowfish theme, made by Nuno Coracao) \u0026ndash; this theme may look slightly familiar ;) Things3 \u0026ndash; yes it exists only for the Apple Ecosystem, but it has a nearly perfect handle on the abstraction of Task Management (and don\u0026rsquo;t abstractions govern the usefulness of software?) Magnet \u0026ndash; I use this on my main machine, a MacBook, and continue to use it because I really enjoy the bindings. Some other window managers for MacOS I would like to check out/recommend are Yabai and Rectangle HHKB2 \u0026ndash; this thing is absolutely awesome and sounds lovely ​\nQuirks # People seem to be divided on learning about other people\u0026rsquo;s intricacies, odd features and characteristics \u0026ndash; some could care less about the stuff that makes you, you, whereas others love to learn about the fine points that comprise their fellow man. For those that like sharing quirks, here are a few of mine:\nUse the key to space code actually insert spaces instead of \\t \u0026ndash; no more and no less than 4 characters are appropriate for a single indentation ​\nRaison d\u0026rsquo;être # Life, as far as I can tell, seems to be a \u0026ldquo;pick your own adventure\u0026rdquo;. Meaning is then something we get/have to define for ourselves. Here are a few items from the current iteration of my Raison d\u0026rsquo;être.\nLearn about Intelligence by Building It Be Serious, without taking Myself too Seriously Expand the Perimeter of my Ignorance by increasing the Area of my Understanding Maximize long-term fun ","date":"1 January 0001","permalink":"/about/","section":"tonkatsu.io","summary":"I am Workin\u0026rsquo; and enjoying this Hero Journey of life. These days this means predominantly spending my time on NLP and RL. Professionally I am a Member of the Technical Staff @ lindy.","title":"About"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"I wager that when You kick the bucket, you will not be wishing you thought less critically in your life \u0026ndash; hopefully you can critically consider a few of the following and make this ride a bit more fun:\n​\nHow far could humanity get naming astrophysical systems/bodies with cool names like Jupiter, Andromeda, Mars, the Jovian System, Alpha Centauri, Oumuamua, or Earth as opposed to the “XP-11213- Ac#4cP” style of naming astronomical objects? When was the last time you thought critically about something? Given the opportunity, would you like to die on Mars? (as opposed to dying on Earth) Is there anything that you, alone, are capable of doing? What would Multi-Threaded Consciousness feel like? (given that the sort of typical consciousness you and I are familiar with is a single threaded set of experiences sorted by time). What might reality be like if our experience of it was happened in parallel? Have you inherited a will (of someone or some set of ideas) or alternatively, are there wills you have inherited but are not cognizant of? Why is the Number 7 the second best number? (42 being the answer to everything kind of cements it in the top position) How much of what you believe is propaganda, or rather how much of what you believe has been arrived at in a non-data driven fashion? What is your life’s optimization equation? In that equation how do you parameterize loss? (is regret minimization the best way to parameterize loss, or what other approaches do you think are worth considering?) What Aesthetic are you embodying/living out in your life? If you have knowingly chosen it, how did you come to make that decision? Is there a line to be drawn between life \u0026amp; non-life? Where might that line exist? Do you Take Orders, Give Orders or Get The Job Done? In the history of humanity, is the advent of civilization a hardware or software upgrade? Is modernism a “set” school of thought/era of ideas, or is the “fully fledged” integration of it still waiting to be developed? (On the successful integration of the old ways with the tools of science and rationalism, being blended together elegantly, prompted by “Seeing Like a State” by SlateStar Codex) Is writing an Essay or making a Presentation just coding a program in the English language to be compiled/executed in someone else’s brain? Remember the Taste of Water For something to be Real (or rather exist) must it then also be True? Or is it possible for something that is False to exist? Knowing what to do precisely isn’t even important, all that is required is a understanding of the “Map” and a direction to move towards Is alcohol a mechanism for regularization? (similar to say \u0026ldquo;dropout\u0026rdquo;) And meditation, spiritual experiences or mushrooms mechanisms for doing data augmentation? How many people get the chance to experience real Romance? What are the fundamental operations of consciousness? What additional good could a human-computer interface like NeuralLink provide when we already have VIM? Does building your personalized version of Arch or Configuring your Vimrc parallel the forging of a lightsaber? Do you ever feel like YOU don’t have enough RAM to Code? Or brainpower to do the work you do? If the human mind does “compression” (shrinks the size of raw data to make storing it more efficient) is that process a global one for \u0026ldquo;Homo Sapiens\u0026rdquo; or is it unique to each individual? Basically, do our brains use the same file extensions? How many “One Way — Do Not Enter” signs have we already opted to enter in the Journey on the Path of Life? How many of those one ways are ultimately positive? How many were negative? What is the viscosity of the Sun? Is it like a giant ball of magma, or closer to a ball of lightning? (It is superheated plasma after-all) In the story of your life, what is the current chapter titled? のみ 星た 言葉 の 棘 が 刺さる ~= The thorns of the words I’ve gulped down stab me — E ve, 2022 Is being vulnerable an honest thing? How many people are on the verge of tears? Our eyes give us a 2D spatial view of the world, how then do we build the 3D conception that we have? (if you have to think about this from scratch) An NPC is one who fails to Reject the Null Hypothesis When in love does the scope of your consciousness expand? Particularly regarding when two individuals become a pair? If God does/were to exist, would it have a God Complex? Does one walk away from their desk whilst a Neural Net Trains or does one sit and wait for it to finish? Linear Algebra is SEXY If you conquer your fear of death, all other fears are a few applications of chain rule away Are Bureaucracies items that you might cultivate in a Garden or Fungi that sneak their way in? — despite the fact that these entities seem to be generally disliked they still persist and if they persist, must be serving some purpose\u0026hellip; Have you ever made Eye Contact with a Painting? Is finding Intelligence a reasonable proxy for Life? What is the average time complexity for a Human to determine what they want to do in this life? How many monitors is just right? What is the difference between predicting an entire sequence of values or each sequential scalar within the sequence? Severus Snape is a Giga-Chad A Quoi Ça Sert L\u0026rsquo;amour? (What is the meaning of love?) Combinatorial flavor space is best explored with un-marinated chadol and banchan. Everyone intends to do their Best Your life is the only adventure that you will get to experience — given that understanding, is it currently the best story that you can come up with? Do as you will — the Rhythm is going to get you. Where does a writer go when they pause? (whilst writing) Do Flies think of us Humans as annoying nuisances (those suckers that bat us away) or as fun past-times (hehe bzzzt bzzt, try and hit me idiot) Do you ever notice the pools of Infinite Peace and Suffering that lay within you? What Evil possesses people to put pictures of Pythons on blog posts/docs about Python related code? Do you hear the Music? Humans typically think in an Object Oriented fashion (at a higher level than animals; accomplished via language) For some, Pathetic is the Aesthetic. What proportion of your work is moonshot stuff? What amount is housekeeping? Does your proportion suit your fancy? Languages are sets of tokens that we can learn shared embeddings of Which examples are more illustrative; what to do or what not to do? Does your Personal Library have within it, a Restricted Section? Which is more important; Work-Life Balance or Your Life\u0026rsquo;s Work? TAKANAKA! One’s level of understanding for a given Topic is proven by their ability to understand Memes about that Topic! It is okay to take short breaks No Hero’s story is complete without suffering and challenge No one is too dumb for Computer Science (s/o JomaTech) Precision does not imply or mean Accuracy. nice Always have an Objective. Age is an accessory that must be dressed correctly Should knowledge/research related objectives reside in your Taxonomy of Tasks? (or should the only thing in the daily taxonomy be the act of research itself, the topic of which can span multiple days) Programming is an embodied thought experiment Bim bom, bim bim bom bom…… ( João Gilberto’s ♥) Unicode and Character Sets, do you understand the wondrous utility they provide? (and the fiascos that prompted the creation of the utility) Write Heroic Code. Do non-trivial things that do not have an explicit payoff! Is Ruthlessness relegated to being a Malevolent trait? or might it be a Benevolent one? True Beauty is not a “conclusion” that we arrive at regarding something (through say; reasoning or a conceptual framework), rather it is something that each individual senses. One Piece will be thought of as Shakespeare in the 2400s Do you ever feel grateful for a Good Night’s Sleep? Moons seem to make up most of the livable real estate in this Universe. Programmers are Alchemists, they Transmute Algorithms into Code. You aren\u0026rsquo;t personally responsible for most Old or Bad code you find on the internet What would a Negative Standard Deviation look like \u0026ndash; if it could be defined? What exactly is going on when you “Think”? Every Plug gets Popped! With great power comes great responsibility! Sci-Fi is a great way to orient a species’ objective functions toward prosperity/thriving To debug better, think of your error logs as a troubled Patient and you as a discerning, interested and caring Psychologist Ramen, Udon or Soba? Sleep with your hands open! What is your “fidget” command in your terminal? I happen to be a ls -l kind of person Saying “Lets go lets go lets go lets go” to yourself in quick succession, with enthusiasm, really does get you into the zone You will get a lot more work done if you are at peace whilst you do it If you program, you’re in good company. Aesthetics are easy to describe but very hard to define The thrill of cracking open a sketchy preworkout Embeddings/Hidden States in Neural Networks = Thoughts in Humans Music is an \u0026lsquo;aural wallpaper\u0026rsquo; The Cards, were never yours to play. What are you willing to do with your life? Absence of Regularization doesn\u0026rsquo;t imply poor Generalization! The work is the reward. Programming provides a better version of Legos Everything is a file! Your reward distribution is non-stationary, so be sure to never stop exploring! Abstractions are omnipresent and we ought to make sure our abstractions are squared away before acting! Why not \u0026ldquo;Brute Force\u0026rdquo; your way to knowledge? If you keep morale high, you will win. Do you have the attitude of a protagonist? Although it is brilliant that general literacy has become cheap — there is an unfortunate \u0026amp; perhaps proportional cost in qualified literacy. Taking notes is basically computing a semantic PCA for the topic at hand. Which is more cool; Linear Algebra or Calculus? Hey You! You’re finally awake. How interesting would your life be if you formed it around that which makes you curious? Why is it that the most brilliant folks are typically scoffed at? All work with a Human in the loop, involves the training of a Neural Network! When you look at the rest of your life and the work yet ahead, aim to look at a horizon nestled atop a vast, romantic, open and exciting sea. “Growth rate” provides a rather useful gradient for the budding Startup. Cats aren’t killers — they’re murderers! Where can one find strength to do that git commit after several hours of hacking your way around a complex codebase and seeing what all has been touched by your ungodly hands after running git status? (asking for a friend) Folks that politely and completely break down ALL of their cardboard boxes have it TOGETHER! Beware the trading-in of; old ideas for 1-dimensional abstractions! After AI kills all of us, it will write a pleasant, non-threating, informational and appropriate poem about the ordeal. Champian is always a good decision. Who knew ~transformers were attending to sequences in 1992? FRATERNITY (skip to 6:40 for the most delectable part) Yea DallE and Stable Diffusion are cool, but that boy AARON is nice with it! Having true Love for someone is to include their success as a term in your value function Somedays you just wanna sudo rm -rf / , eat a cookie! Is editing a tmux config @ 9:20pm on a Sunday the BEST possible use of one’s time? Always Tugging my sleeve. Don’t be afraid to drink a little Workohol. \u0026ldquo;Embeddings\u0026rdquo; are DEFINITELY “ thoughts.” If the Policy that brings success in your workplace is intertwined with anything like “Internal Politics”, seek a new workplace. Saudade is ~= to this. A depiction of what it is like to live in San Francisco as one not part of it. Beware of writing code that is not worthy of a git commit. Don’t forget to think! Also do not forget why it is you do what you do. If on reminding yourself of this, you find that your ‘Why’ has become obsolete, change what you do in order to align with a more suitable why. AI∀ GPUs really do go BRRRRRR! The fact that we can sample snippets of reality from a “Latent” vector is so cool! ","date":"1 January 0001","permalink":"/ponderings/","section":"tonkatsu.io","summary":"I wager that when You kick the bucket, you will not be wishing you thought less critically in your life \u0026ndash; hopefully you can critically consider a few of the following and make this ride a bit more fun:","title":"Ponderings"},{"content":"","date":"1 January 0001","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"}]